
# ุฅููุงู ุงูุตูุฑ

ุชุนุฏ ุชูููุฉ ุฅููุงู ุงูุตูุฑ (Inpainting) ุฃุฏุงุฉ ูููุฏุฉ ูุฅุตูุงุญ ุงูุตูุฑ ุนู ุทุฑูู ุงุณุชุจุฏุงู ุฃู ุชุนุฏูู ููุงุทู ูุญุฏุฏุฉ ูููุง. ูููู ุงุณุชุฎุฏุงููุง ูุฅุฒุงูุฉ ุงูุนููุจ ูุงูุชุดููุดุ ุฃู ุญุชู ุงุณุชุจุฏุงู ููุทูุฉ ูู ุงูุตูุฑุฉ ุจุดูุก ุฌุฏูุฏ ุชูุงููุง. ุชุนุชูุฏ ูุฐู ุงูุชูููุฉ ุนูู ููุงุน ูุชุญุฏูุฏ ุงูููุงุทู ุงููุฑุงุฏ ููุคูุง ูู ุงูุตูุฑุฉุ ุญูุซ ุชูุซู ุงูุจูุณูุงุช ุงูุจูุถุงุก ุงูููุทูุฉ ุงููุฑุงุฏ ุชุนุฏูููุงุ ุจูููุง ุชูุซู ุงูุจูุณูุงุช ุงูุณูุฏุงุก ุงูููุทูุฉ ุงูุชู ุณูุชู ุงูุงุญุชูุงุธ ุจูุง ุฏูู ุชุบููุฑ. ูุชู ููุก ุงูุจูุณูุงุช ุงูุจูุถุงุก ุจูุงุกู ุนูู ุงููุญุชูู ุงููุทููุจ ูู ุฎูุงู ุงููุต ุงููุตูู.

ูุน ููุชุจุฉ ๐ค Diffusersุ ููููู ุงูููุงู ุจุฅููุงู ุงูุตูุฑ ุนูู ุงููุญู ุงูุชุงูู:

1. ูู ุจุชุญููู ููุทุฉ ุชูุชูุด (Checkpoint) ุฎุงุตุฉ ุจุฅููุงู ุงูุตูุฑ ุจุงุณุชุฎุฏุงู ุงููุฆุฉ [`AutoPipelineForInpainting`]. ุณูุชู ุงููุดู ุชููุงุฆููุง ุนู ูุฆุฉ ุงูุฃูุงุจูุจ ุงูููุงุณุจุฉ ูุชุญููููุง ุจูุงุกู ุนูู ููุทุฉ ุงูุชูุชูุด:

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
"kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# ุงุญุฐู ุงูุณุทุฑ ุงูุชุงูู ุฅุฐุง ูู ููู xFormers ูุซุจุชูุง ุฃู ุฅุฐุง ูุงู ูุฏูู PyTorch 2.0 ุฃู ุฃุนูู ูุซุจุชูุง
pipeline.enable_xformers_memory_efficient_attention()
```

<Tip>
ุณุชูุงุญุธ ุฎูุงู ูุฐุง ุงูุฏููู ุฃููุง ูุณุชุฎุฏู [`~DiffusionPipeline.enable_model_cpu_offload`] ู [`~DiffusionPipeline.enable_xformers_memory_efficient_attention`]ุ ูุชูููุฑ ุงูุฐุงูุฑุฉ ูุฒูุงุฏุฉ ุณุฑุนุฉ ุงูุงุณุชุฏูุงู. ุฅุฐุง ููุช ุชุณุชุฎุฏู PyTorch 2.0ุ ููุง ููุฒู ุงุณุชุฏุนุงุก [`~DiffusionPipeline.enable_xformers_memory_efficient_attention`] ุนูู ุฎุท ุฃูุงุจูุจู ูุฃููุง ุณุชุณุชุฎุฏู ุจุงููุนู ุงูุชุจุงู [scaled-dot product](../optimization/torch2.0#scaled-dot-product-attention) ุงูุฃุตูู ูู PyTorch 2.0.
</Tip>

2. ูู ุจุชุญููู ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉ ูุตูุฑุฉ ุงูููุงุน:

```py
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")
```

3. ูู ุจุฅูุดุงุก ูุต ูุตูู ูุฅููุงู ุงูุตูุฑุฉุ ุซู ูุฑุฑู ุฅูู ุฎุท ุงูุฃูุงุจูุจ ูุน ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉ ูุตูุฑุฉ ุงูููุงุน:

```py
prompt = "a black cat with glowing eyes, cute, adorable, disney, pixar, highly detailed, 8k"
negative_prompt = "bad anatomy, deformed, ugly, disfigured"
image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">base image</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">mask image</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-cat.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">generated image</figcaption>
  </div>
</div>


## ุฅูุดุงุก ุตูุฑุฉ ุงูููุงุน

ุนูู ุงูุฑุบู ูู ุชูููุฑ ุตูุฑุฉ ุงูููุงุน ูู ุฌููุน ุฃูุซูุฉ ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ูู ูุฐุง ุงูุฏูููุ ุฅูุง ุฃูู ููููู ุฅููุงู ุงูุตูุฑ ุงูุฎุงุตุฉ ุจูุ ูููู ุณุชุญุชุงุฌ ุฅูู ุฅูุดุงุก ุตูุฑุฉ ููุงุน ููุง. ููููู ุงุณุชุฎุฏุงู ุงููุณุงุญุฉ ุฃุฏูุงู ูุฅูุดุงุก ุตูุฑุฉ ููุงุน ุจุณูููุฉ.

ูู ุจุชุญููู ุตูุฑุฉ ุฃุณุงุณูุฉ ูุฅููุงููุงุ ุซู ุงุณุชุฎุฏู ุฃุฏุงุฉ ุงูุฑุณู ูุชูููู ุงูููุงุน. ุจูุฌุฑุฏ ุงูุงูุชูุงุกุ ุงููุฑ ููู "Run" ูุฅูุดุงุก ุตูุฑุฉ ุงูููุงุน ูุชุญููููุง.

<iframe
  src="https://stevhliu-inpaint-mask-maker.hf.space"
  frameborder="0"
  width="850"
  height="450"
></iframe>

## ุฏุฑุฌุฉ ุถุจุงุจูุฉ ุงูููุงุน

ุชููุฑ ุทุฑููุฉ [`~VaeImageProcessor.blur`] ุฎูุงุฑูุง ูุทุฑููุฉ ูุฒุฌ ุงูุตูุฑุฉ ุงูุฃุตููุฉ ูููุทูุฉ ุงูุฅููุงู. ูุชู ุชุญุฏูุฏ ููุฏุงุฑ ุงูุถุจุงุจูุฉ ุจูุงุณุทุฉ ูุนุงูู `blur_factor`. ูุคุฏู ุฒูุงุฏุฉ `blur_factor` ุฅูู ุฒูุงุฏุฉ ููุฏุงุฑ ุงูุถุจุงุจูุฉ ุงููุทุจูุฉ ุนูู ุญูุงู ุงูููุงุนุ ููุง ูุฌุนู ุงูุงูุชูุงู ุจูู ุงูุตูุฑุฉ ุงูุฃุตููุฉ ูููุทูุฉ ุงูุฅููุงู ุฃูุซุฑ ูุนููุฉ. ุจูููุง ูุญุงูุธ ูุนุงูู `blur_factor` ุงูููุฎูุถ ุฃู ุงูุตูุฑู ุนูู ุญูุงู ุงูููุงุน ุงูุญุงุฏุฉ.

ูุงุณุชุฎุฏุงู ูุฐู ุงูููุฒุฉุ ูู ุจุฅูุดุงุก ููุงุน ุถุจุงุจู ุจุงุณุชุฎุฏุงู ูุนุงูุฌ ุงูุตูุฑ:

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image
from PIL import Image

pipeline = AutoPipelineForInpainting.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16).to('cuda')

mask = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png")
blurred_mask = pipeline.mask_processor.blur(mask, blur_factor=33)
blurred_mask
```

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">mask with no blur</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/mask_blurred.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">mask with blur applied</figcaption>
  </div>
</div>

## ุงูููุงุฐุฌ ุงูุดุงุฆุนุฉ

ูู ุจูู ุงูููุงุฐุฌ ุงูุฃูุซุฑ ุดุนุจูุฉ ูุฅููุงู ุงูุตูุฑ: [Stable Diffusion Inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting)ุ ู [Stable Diffusion XL (SDXL) Inpainting](https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1)ุ ู [Kandinsky 2.2 Inpainting](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint). ุนุงุฏุฉ ูุง ููุชุฌ ูููุฐุฌ SDXL ุตูุฑูุง ุฐุงุช ุฏูุฉ ุฃุนูู ูู Stable Diffusion v1.5ุ ููุง ุฃู Kandinsky 2.2 ูุงุฏุฑ ุฃูุถูุง ุนูู ุชูููุฏ ุตูุฑ ุนุงููุฉ ุงูุฌูุฏุฉ.

### Stable Diffusion Inpainting

Stable Diffusion Inpainting ูู ูููุฐุฌ ุงูุชุดุงุฑ ูุงุชููู ุชูุช ูุนุงูุฑุชู ุนูู ุตูุฑ ุจุญุฌู 512x512 ูุฅููุงู ุงูุตูุฑ. ุฅูู ููุทุฉ ุงูุทูุงู ุฌูุฏุฉ ูุฃูู ุณุฑูุน ูุณุจููุง ูููุชุฌ ุตูุฑูุง ุนุงููุฉ ุงูุฌูุฏุฉ. ูุงุณุชุฎุฏุงู ูุฐุง ุงููููุฐุฌ ูุฅููุงู ุงูุตูุฑุ ุณุชุญุชุงุฌ ุฅูู ุชูุฑูุฑ ูุต ูุตูู ูุตูุฑุฉ ุฃุณุงุณูุฉ ูุตูุฑุฉ ููุงุน ุฅูู ุฎุท ุงูุฃูุงุจูุจ:

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
"runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# ุงุญุฐู ุงูุณุทุฑ ุงูุชุงูู ุฅุฐุง ูู ููู xFormers ูุซุจุชูุง ุฃู ุฅุฐุง ูุงู ูุฏูู PyTorch 2.0 ุฃู ุฃุนูู ูุซุจุชูุง
pipeline.enable_xformers_memory_efficient_attention()

# ูู ุจุชุญููู ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉ ูุตูุฑุฉ ุงูููุงุน
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

### Stable Diffusion XL (SDXL) Inpainting

SDXL ูู ุฅุตุฏุงุฑ ุฃูุจุฑ ูุฃูุซุฑ ููุฉ ูู Stable Diffusion v1.5. ูููู ุฃู ูุชุจุน ูุฐุง ุงููููุฐุฌ ุนูููุฉ ููููุฉ ูู ูุฑุญูุชูู (ุนูู ุงูุฑุบู ูู ุฃูู ูููู ุงุณุชุฎุฏุงู ูู ูููุฐุฌ ุจููุฑุฏู)ุ ุญูุซ ูููู ุงููููุฐุฌ ุงูุฃุณุงุณู ุจุชูููุฏ ุตูุฑุฉุ ุซู ูููู ูููุฐุฌ ุงูุชุญุณูู ุจุฃุฎุฐ ุชูู ุงูุตูุฑุฉ ูุชุญุณูู ุชูุงุตูููุง ูุฌูุฏุชูุง. ููููู ุงูุงุทูุงุน ุนูู ุฏููู [SDXL](sdxl) ููุญุตูู ุนูู ุฏููู ุฃูุซุฑ ุดูููุงู ุญูู ููููุฉ ุงุณุชุฎุฏุงู SDXL ูุชูููู ูุนุงููู.

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
"diffusers/stable-diffusion-xl-1.0-inpainting-0.1", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# ุงุญุฐู ุงูุณุทุฑ ุงูุชุงูู ุฅุฐุง ูู ููู xFormers ูุซุจุชูุง ุฃู ุฅุฐุง ูุงู ูุฏูู PyTorch 2.0 ุฃู ุฃุนูู ูุซุจุชูุง
pipeline.enable_xformers_memory_efficient_attention()

# ูู ุจุชุญููู ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉ ูุตูุฑุฉ ุงูููุงุน
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_Intersecting image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

### Kandinsky 2.2 Inpainting

ุชุชุดุงุจู ุนุงุฆูุฉ ููุงุฐุฌ Kandinsky ูุน SDXL ูุฃููุง ุชุณุชุฎุฏู ูููุฐุฌูู ุฃูุถูุงุ ุญูุซ ูููู ูููุฐุฌ ุงูุตูุฑุฉ ุงูุฃูููุฉ ุจุฅูุดุงุก ุชุถูููุงุช ุงูุตูุฑุฉุ ูููุดุฆ ูููุฐุฌ ุงูุงูุชุดุงุฑ ุงูุตูุฑ ูููุง. ููููู ุชุญููู ุตูุฑุฉ ุฃูููุฉ ููููุฐุฌ ุงูุชุดุงุฑ ุจุดูู ูููุตูุ ูููู ุฃุณูู ุทุฑููุฉ ูุงุณุชุฎุฏุงู Kandinsky 2.2 ูู ุชุญูููู ูู ูุฆุฉ [`AutoPipelineForInpainting`] ุงูุชู ุชุณุชุฎุฏู [`KandinskyV22InpaintCombinedPipeline`] ุชุญุช ุงูุบุทุงุก.

ููููู ุงูุนุซูุฑ ุนูู ุงููุต ุงูุจุฑูุฌู ุงููุงูู ุฃุฏูุงู. ูุงุญุธ ุฃูู ูุณุชุฎุฏู ููุชุจุฉ xFormersุ ูุฐุง ุชุฃูุฏ ูู ุชุซุจูุชูุง ูุจู ุชุดุบููู.

ุชูุธูุฑ ุงูุตูุฑ ุฃุฏูุงู ูุชุงุฆุฌ ุงุณุชุฎุฏุงู Kandinsky 2.2 ูุฅููุงู ุงูุตูุฑุฉ ุงููุงูุตุฉ. ูุงุญุธ ููู ุฃู ุงููุชูุฌุฉ ุฃูุซุฑ ุชูุตููุงู ููุถูุญูุง ูู SD ูSDXL.

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```


<div class="flex flex-row gap-4">
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉ</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-sdv1.5.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">Stable Diffusion Inpainting</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-sdxl.png"/>
<figcaption class="mt-turut text-center text-sm text-gray-500">Stable Diffusion XL Inpainting</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-kandinsky.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">Kandinsky 2.2 Inpainting</figcaption>
</div>
</div>


## ููุงุท ุชูุชูุด ุบูุฑ ุฎุงุตุฉ ุจู Inpaint

ุญุชู ุงูุขูุ ุงุณุชุฎุฏู ูุฐุง ุงูุฏููู ููุงุท ุชูุชูุด ุฎุงุตุฉ ุจู Inpaint ูุซู [runwayml/stable-diffusion-inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting). ูููู ููููู ุฃูุถูุง ุงุณุชุฎุฏุงู ููุงุท ุชูุชูุด ุนุงุฏูุฉ ูุซู [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5). ุฏุนููุง ููุงุฑู ูุชุงุฆุฌ ููุทุชู ุงูุชูุชูุด.

ุงูุตูุฑุฉ ุนูู ุงููุณุงุฑ ููููุฏุฉ ูู ููุทุฉ ุชูุชูุด ุนุงุฏูุฉุ ูุงูุตูุฑุฉ ุนูู ุงููููู ูู ููุทุฉ ุชูุชูุด Inpaint. ุณุชูุงุญุธ ุนูู ุงูููุฑ ุฃู ุงูุตูุฑุฉ ุนูู ุงููุณุงุฑ ููุณุช ุจููุณ ุงูุฌูุฏุฉุ ูููููู ุฑุคูุฉ ูุฎุทุท ุงูููุทูุฉ ุงูุชู ูููุชุฑุถ ุฃู ุชููู ุจูุง ุงููููุฐุฌ Inpaint. ุงูุตูุฑุฉ ุนูู ุงููููู ุฃูุธู ุจูุซูุฑุ ูุชุธูุฑ ุงูููุทูุฉ ุงูุชู ุชู ุฅุตูุงุญูุง ุจุดูู ุฃูุซุฑ ุทุจูุนูุฉ.

<hfoptions id="regular-specific">
<hfoption id="runwayml/stable-diffusion-v1-5">

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

</hfoption>
<hfoption id="runwayml/stable-diffusion-inpainting">

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

</hfoption>
</hfoptions>

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/non-inpaint-specific.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">runwayml/stable-diffusion-v1-5</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-specific.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">runwayml/stable-diffusion-inpainting</figcaption>
  </div>
</div>


ุนูู ุงูุฑุบู ูู ุฐููุ ุจุงููุณุจุฉ ููููุงู ุงูุฃุณุงุณูุฉ ูุซู ุฅุฒุงูุฉ ูุงุฆู ูู ุตูุฑุฉ (ูุซู ุงูุตุฎูุฑ ุนูู ุงูุทุฑููุ ุนูู ุณุจูู ุงููุซุงู)ุ ูุฅู ููุทุฉ ุชูุชูุด ุนุงุฏูุฉ ุชุนุทู ูุชุงุฆุฌ ุฌูุฏุฉ ุฌุฏูุง. ููุณ ููุงู ูุฑู ููุญูุธ ุจูู ููุทุฉ ุงูุชูุชูุด ุงูุนุงุฏูุฉ ูููุทุฉ ุชูุชูุด Inpaint.

<hfoptions id="inpaint">
<hfoption id="runwayml/stable-diffusion-v1-5">

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/road-mask.png")

image = pipeline(prompt="road", image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

</hfoption>
<hfoption id="runwayml/stable-diffusion-inpaint">

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/road-mask.png")

image = pipeline(prompt="road", image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

</hfoption>
</hfoptions>

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/regular-inpaint-basic.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">runwayml/stable-diffusion-v1-5</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/specific-inpaint-basic.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">runwayml/stable-diffusion-inpainting</figcaption>
  </div>
</div>


ุงูููุงูุถุฉ ูุงุณุชุฎุฏุงู ููุทุฉ ุชูุชูุด ุบูุฑ ุฎุงุตุฉ ุจู Inpaint ูู ุฃู ุฌูุฏุฉ ุงูุตูุฑุฉ ุงูุฅุฌูุงููุฉ ูุฏ ุชููู ุฃููุ ูููููุง ุชููู ุนููููุง ุฅูู ุงูุญูุงุธ ุนูู ููุทูุฉ ุงูููุงุน (ููุฐุง ูู ุงูุณุจุจ ูู ุฅููุงููุฉ ุฑุคูุฉ ูุฎุทุท ุงูููุงุน). ูุชู ุชุฏุฑูุจ ููุงุท ุชูุชูุด Inpaint ุงูุฎุงุตุฉ ุนู ูุตุฏ ูุฅูุดุงุก ุตูุฑ ุฐุงุช ุฌูุฏุฉ ุฃุนููุ ูุงูุชู ุชุชุถูู ุฅูุดุงุก ุงูุชูุงู ุฃูุซุฑ ุทุจูุนูุฉ ุจูู ุงูููุงุทู ุงููููุนุฉ ูุบูุฑ ุงููููุนุฉ. ููุชูุฌุฉ ูุฐููุ ูู ุงููุฑุฌุญ ุฃู ุชุบูุฑ ูุฐู ุงูููุงุท ููุทูุฉ ุบูุฑ ุงููููุนุฉ.

ุฅุฐุง ูุงู ุงูุญูุงุธ ุนูู ุงูููุทูุฉ ุบูุฑ ุงููููุนุฉ ุฃูุฑูุง ููููุง ููููุชูุ ูููููู ุงุณุชุฎุฏุงู ุทุฑููุฉ [`VaeImageProcessor.apply_overlay`] ูุฅุฌุจุงุฑ ุงูููุทูุฉ ุบูุฑ ุงููููุนุฉ ููุตูุฑุฉ ุนูู ุงูุจูุงุก ููุง ูู ุนูู ุญุณุงุจ ุจุนุถ ุงูุงูุชูุงูุงุช ุบูุฑ ุงูุทุจูุนูุฉ ุจูู ุงูููุงุทู ุงููููุนุฉ ูุบูุฑ ุงููููุนุฉ.


```py
import PIL
import numpy as np
import torch

from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

device = "cuda"
pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting",
    torch_dtype=torch.float16,
)
pipeline = pipeline.to(device)

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

init_image = load_image(img_url).resize((512, 512))
mask_image = load_image(mask_url).resize((512, 512))

prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
repainted_image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]
repainted_image.save("repainted_image.png")

unmasked_unchanged_image = pipeline.image_processor.apply_overlay(mask_image, init_image, repainted_image)
unmasked_unchanged_image.save("force_unmasked_unchanged.png")
make_image_grid([init_image, mask_image, repainted_image, unmasked_unchanged_image], rows=2, cols=2)
```



## ุชูููู ูุนููุงุช ุงูุฃูุงุจูุจ

ุชุนุชูุฏ ููุฒุงุช ุงูุตูุฑุฉ - ูุซู ุงูุฌูุฏุฉ ู"ุงูุฅุจุฏุงุน" - ุนูู ูุนููุงุช ุงูุฃูุงุจูุจ. ูู ุงูููู ูุนุฑูุฉ ูุง ุชูุนูู ูุฐู ุงููุนููุงุช ููุญุตูู ุนูู ุงููุชุงุฆุฌ ุงููุฑุฌูุฉ. ุฏุนููุง ูููู ูุธุฑุฉ ุนูู ุฃูู ุงููุนููุงุช ููุฑู ููู ูุคุซุฑ ุชุบููุฑูุง ุนูู ุงูุฅุฎุฑุงุฌ.

### ุงูููุฉ

`strength` ูู ูููุงุณ ููููุฉ ุงูุถูุถุงุก ุงููุถุงูุฉ ุฅูู ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉุ ูุงูุชู ุชุคุซุฑ ุนูู ูุฏู ุชุดุงุจู ุงูุฅุฎุฑุงุฌ ูุน ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉ.

- ๐ ูููุฉ ุนุงููุฉ ูู `strength` ุชุนูู ุฅุถุงูุฉ ุงููุฒูุฏ ูู ุงูุถูุถุงุก ุฅูู ุงูุตูุฑุฉ ูุชุณุชุบุฑู ุนูููุฉ ุฅุฒุงูุฉ ุงูุชุดููุด ููุชูุง ุฃุทููุ ููููู ุณุชุญุตู ุนูู ุตูุฑ ุนุงููุฉ ุงูุฌูุฏุฉ ุชุฎุชูู ุฃูุซุฑ ุนู ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉ

- ๐ ูููุฉ ููุฎูุถุฉ ูู `strength` ุชุนูู ุฅุถุงูุฉ ูุฏุฑ ุฃูู ูู ุงูุถูุถุงุก ุฅูู ุงูุตูุฑุฉ ูุชููู ุนูููุฉ ุฅุฒุงูุฉ ุงูุชุดููุด ุฃุณุฑุนุ ูููู ูุฏ ูุง ุชููู ุฌูุฏุฉ ุงูุตูุฑุฉ ุฌูุฏุฉ ููุฏ ุชุดุจู ุงูุตูุฑุฉ ุงููููุฏุฉ ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉ ุฃูุซุฑ


```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.6).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

<div class="flex flex-row gap-4">
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-0.6.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">strength = 0.6</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-0.8.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">strength = 0.8</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-1.0.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">strength = 1.0</figcaption>
  </div>
</div>


### ูููุงุณ ุงูุชูุฌูู

`guidance_scale` ูุคุซุฑ ุนูู ูุฏู ุชูุงูู ููุฌู ุงููุต ูุงูุตูุฑุฉ ุงููููุฏุฉ.

- ๐ ูููุฉ ุนุงููุฉ ูู `guidance_scale` ุชุนูู ุฃู ุงูููุฌู ูุงูุตูุฑุฉ ุงููููุฏุฉ ูุชูุงููุงู ุจุดูู ูุซููุ ูุฐุง ูุฅู ุงูุฅุฎุฑุงุฌ ูู ุชูุณูุฑ ุฃูุซุฑ ุตุฑุงูุฉ ููููุฌู

- ๐ ูููุฉ ููุฎูุถุฉ ูู `guidance_scale` ุชุนูู ุฃู ุงูููุฌู ูุงูุตูุฑุฉ ุงููููุฏุฉ ูุชูุงููุงู ุจุดูู ูุถูุงุถุ ูุฐุง ููุฏ ูููู ุงูุฅุฎุฑุงุฌ ุฃูุซุฑ ุชููุนูุง ุนู ุงูููุฌู

ููููู ุงุณุชุฎุฏุงู `strength` ู`guidance_scale` ูุนูุง ููุฒูุฏ ูู ุงูุชุญูู ูู ูุฏู ุชุนุจูุฑูุฉ ุงููููุฐุฌ. ุนูู ุณุจูู ุงููุซุงูุ ูููุญ ูุฒูุฌ ูู ุงูููู ุงูุนุงููุฉ ูู `strength` ู`guidance_scale` ุงููููุฐุฌ ุฃูุจุฑ ูุฏุฑ ูู ุงูุญุฑูุฉ ุงูุฅุจุฏุงุนูุฉ.

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, guidance_scale=2.5).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

<div class="flex flex-row gap-4">
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-2.5.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 2.5</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-7.5.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 7.5</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-12.5.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 12.5</figcaption>
  </div>
</div>


### ููุฌู ุณูุจู

ููุชุฑุถ ุงูููุฌู ุงูุณูุจู ุงูุฏูุฑ ุงููุนุงูุณ ููููุฌูุ ููู ููุฌู ุงููููุฐุฌ ุจุนูุฏูุง ุนู ุชูููุฏ ุฃุดูุงุก ูุนููุฉ ูู ุตูุฑุฉ. ููุฐุง ูููุฏ ูุชุญุณูู ุฌูุฏุฉ ุงูุตูุฑุฉ ุจุณุฑุนุฉ ูููุน ุงููููุฐุฌ ูู ุชูููุฏ ุฃุดูุงุก ูุง ุชุฑูุฏูุง.

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
negative_prompt = "bad architecture, unstable, poor details, blurry"
image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```

<div class="flex justify-center">
  <figure>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-negative.png" />
    <figcaption class="text-center">negative_prompt = "bad architecture, unstable, poor details, blurry"</figcaption>
  </figure>
</div>


### ููุงุน ุงูุญุดู ุงููุญุตูู

ุชุชูุซู ุฅุญุฏู ุทุฑู ุฒูุงุฏุฉ ุฌูุฏุฉ ุตูุฑุฉ ุงูุญุดู ูู ุงุณุชุฎุฏุงู ูุนููุฉ [`padding_mask_crop`](https://huggingface.co/docs/diffusers/v0.25.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.__call__.padding_mask_crop). ุนูุฏูุง ูุชู ุชูููู ูุฐุง ุงูุฎูุงุฑุ ูุฅูู ูููู ุจุงูุชุตุงุต ุงูููุทูุฉ ุงููููุนุฉ ุจุจุนุถ ุงูุญุดู ุงูุฐู ูุญุฏุฏู ุงููุณุชุฎุฏูุ ููุง ุณูููู ุจุงูุชุตุงุต ููุณ ุงูููุทูุฉ ูู ุงูุตูุฑุฉ ุงูุฃุตููุฉ. ูุชู ุชูุจูุฑ ูู ูู ุงูุตูุฑุฉ ูุงูููุงุน ุฅูู ุฏูุฉ ุฃุนูู ููุญุดูุ ุซู ูุชู ูุถุนููุง ููู ุงูุตูุฑุฉ ุงูุฃุตููุฉ. ูุฐู ุทุฑููุฉ ุณุฑูุนุฉ ูุณููุฉ ูุชุญุณูู ุฌูุฏุฉ ุงูุตูุฑุฉ ุฏูู ุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ ูููุตู ูุซู [`StableDiffusionUpscalePipeline`].

ุฃุถู ูุนููุฉ `padding_mask_crop` ุฅูู ููุงููุฉ ุฎุท ุงูุฃูุงุจูุจ ููู ุจุชุนููููุง ุนูู ูููุฉ ุงูุญุดู ุงููุฑุบูุจุฉ.
```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image
from PIL import Image

generator = torch.Generator(device='cuda').manual_seed(0)
pipeline = AutoPipelineForInpainting.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16).to('cuda')

base = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore.png")
mask = load_image("https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png")

image = pipeline("boat", image=base, mask_image=mask, strength=0.75, generator=generator, padding_mask_crop=32).images[0]
image
```

<div class="flex gap-4">
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/baseline_inpaint.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">default inpaint image</figcaption>
  </div>
  <div>
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/padding_mask_crop_inpaint.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">inpaint image with `padding_mask_crop` enabled</figcaption>
  </div>
</div>


### ุฎุทูุท ุฃูุงุจูุจ ุงูุญุดู ุงููุชุณูุณูุฉ

ูููู ุชุณูุณู [`AutoPipelineForInpainting`] ูุน ุฎุทูุท ุฃูุงุจูุจ ุฃุฎุฑู ูู ๐ค Diffusers ูุชุญุฑูุฑ ุฅุฎุฑุงุฌูุง. ุบุงูุจูุง ูุง ูููู ูุฐุง ูููุฏูุง ูุชุญุณูู ุฌูุฏุฉ ุงูุฅุฎุฑุงุฌ ูู ุฎุทูุท ุฃูุงุจูุจ ุงูุงูุชุดุงุฑ ุงูุฃุฎุฑูุ ูุฅุฐุง ููุช ุชุณุชุฎุฏู ุฎุทูุท ุฃูุงุจูุจ ูุชุนุฏุฏุฉุ ููุฏ ูููู ูู ุงูุฃูุซุฑ ููุงุกุฉ ูู ุงูุฐุงูุฑุฉ ุชุณูุณููุง ูุนูุง ููุญูุงุธ ุนูู ุงูุฅุฎุฑุงุฌ ูู ูุณุงุญุฉ ุฎููุฉ ูุฅุนุงุฏุฉ ุงุณุชุฎุฏุงู ููุณ ููููุงุช ุฎุท ุงูุฃูุงุจูุจ.

### ุฑุจุท ุงููุต ุจุงูุตูุฑุฉ ุซู ุฅุตูุงุญูุง

ูุชูุญ ุฑุจุท ุฎุท ุฃูุงุจูุจ ูู ุงููุต ุฅูู ุงูุตูุฑุฉ ูุฅุตูุงุญูุง ุฅููุงููุฉ ุฅุตูุงุญ ุงูุตูุฑุฉ ุงููููุฏุฉุ ููุง ููุฒูู ุชูููุฑ ุตูุฑุฉ ุฃุณุงุณูุฉ ููุจุฏุก. ูุฌุนู ูุฐุง ุงูุฃูุฑ ูุฑูุญูุง ูุชุญุฑูุฑ ูุฎุฑุฌุงุช ุงููุต ุฅูู ุงูุตูุฑุฉ ุงูููุถูุฉ ูุฏูู ุฏูู ุงูุญุงุฌุฉ ุฅูู ุฅูุดุงุก ุตูุฑุฉ ุฌุฏูุฏุฉ ุชูุงููุง.

ุงุจุฏุฃ ุจุฎุท ุฃูุงุจูุจ ูู ุงููุต ุฅูู ุงูุตูุฑุฉ ูุฅูุดุงุก ููุนุฉ:


```py
import torch
from diffusers import AutoPipelineForText2Image, AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

text2image = pipeline("concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k").images[0]
```


ูู ุจุชุญููู ุตูุฑุฉ ุงูููุงุน ูู ุงูุฅุฎุฑุงุฌ ุฃุนูุงู:
```py
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_text-chain-mask.png")
```

ูุงูุขู ุฏุนููุง ูุตูุญ ุงูููุทูุฉ ุงููููุนุฉ ุจุดูุงู:

```py
pipeline = AutoPipelineForInpainting.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

prompt = "digital painting of a fantasy waterfall, cloudy"
image = pipeline(prompt=prompt, image=text2image, mask_image=mask_image).images[0]
make_image_grid([text2image, mask_image, image], rows=1, cols=3)
```

<div class="flex flex-row gap-4">
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-text-chain.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">text-to-image</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-text-chain-out.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">inpaint</figcaption>
  </div>
</div>

### ุฅุตูุงุญ ุฅูู ุตูุฑุฉ ุฅูู ุตูุฑุฉ

ููููู ุฃูุถูุง ุฑุจุท ุฎุท ุฃูุงุจูุจ ุงูุฅุตูุงุญ ูุจู ุฎุท ุฃูุงุจูุจ ุขุฎุฑ ูุซู ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ุฃู ุฃุฏุงุฉ ุชูุจูุฑ ูุชุญุณูู ุงูุฌูุฏุฉ.

ุงุจุฏุฃ ุจุฅุตูุงุญ ุตูุฑุฉ:

```py
import torch
from diffusers import AutoPipelineForInpainting, AutoPipelineForImage2Image
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image_inpainting = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]

# resize image to 1024x1024 for SDXL
image_inpainting = image_inpainting.resize((1024, 1024))
```

ุงูุขู ุฏุนููุง ููุฑุฑ ุงูุตูุฑุฉ ุฅูู ุฎุท ุฃูุงุจูุจ ุฅุตูุงุญ ุขุฎุฑ ูุน ูููุฐุฌ SDXL refiner ูุชุญุณูู ุชูุงุตูู ุงูุตูุฑุฉ ูุงูุฌูุฏุฉ:

```py
pipeline = AutoPipelineForInpainting.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt=prompt, image=image_inpainting, mask_image=mask_image, output_type="latent").images[0]
```

<Tip>
ูู ุงูููู ุชุญุฏูุฏ output_type="latent" ูู ุฎุท ุงูุฃูุงุจูุจ ููุญูุงุธ ุนูู ุฌููุน ุงูุฅุฎุฑุงุฌ ูู ูุณุงุญุฉ ุงููุงููุฉ ูุชุฌูุจ ุฎุทูุฉ ุงูุชุฑููุฒ ูู ุงูุชุฑููุฒ ุบูุฑ ุงูุถุฑูุฑูุฉ. ูุนูู ูุฐุง ููุท ุฅุฐุง ูุงูุช ุฎุทูุท ุงูุฃูุงุจูุจ ุงููุชุณูุณูุฉ ุชุณุชุฎุฏู ููุณ VAE. ุนูู ุณุจูู ุงููุซุงูุ ูู ูุณู [ุงููุต ุฅูู ุงูุตูุฑุฉ ุฅูู ุงูุฅุตูุงุญ](#text-to-image-to-inpaint)ุ ูุณุชุฎุฏู Kandinsky 2.2 ูุฆุฉ VAE ูุฎุชููุฉ ุนู ูููุฐุฌ Stable Diffusion ูุฐูู ูู ูุนูู. ูููู ุฅุฐุง ุงุณุชุฎุฏูุช Stable Diffusion v1.5 ููู ูู ุฎุทูุท ุงูุฃูุงุจูุจุ ูููููู ุงูุญูุงุธ ุนูู ูู ุดูุก ูู ูุณุงุญุฉ ุงููุงููุฉ ูุฃููุง ุชุณุชุฎุฏู ุฌููุนูุง [`AutoencoderKL`].
</Tip>

ุฃุฎูุฑูุงุ ููููู ุชูุฑูุฑ ูุฐู ุงูุตูุฑุฉ ุฅูู ุฎุท ุฃูุงุจูุจ ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ููุถุน ุงูููุณุงุช ุงูุฃุฎูุฑุฉ ุนูููุง. ูู ุงูุฃูุซุฑ ููุงุกุฉ ุงุณุชุฎุฏุงู ุทุฑููุฉ [`~AutoPipelineForImage2Image.from_pipe`] ูุฅุนุงุฏุฉ ุงุณุชุฎุฏุงู ููููุงุช ุฎุท ุงูุฃูุงุจูุจ ุงูููุฌูุฏุฉุ ูุชุฌูุจ ุชุญููู ุฌููุน ููููุงุช ุฎุท ุงูุฃูุงุจูุจ ูู ุงูุฐุงูุฑุฉ ูุฑุฉ ุฃุฎุฑู ุฏูู ุฏุงุน.

```py
pipeline = AutoPipelineForImage2Image.from_pipe(pipeline)
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt=prompt, image=image).images[0]
make_image_grid([init_image, mask_image, image_inpainting, image], rows=2, cols=2)
```

<div class="flex flex-row gap-4">
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">ุงูุตูุฑุฉ ุงูุฃูููุฉ</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-to-image-chain.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">ุฅุตูุงุญ</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-to-image-final.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ</figcaption>
</div>
</div>

ูู ุงููุงูุนุ ุงูุฅุตูุงุญ ูุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ููุงู ูุชุดุงุจูุฉ ุฌุฏูุง. ุชููู ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ุจุชูููุฏ ุตูุฑุฉ ุฌุฏูุฏุฉ ุชุดุจู ุงูุตูุฑุฉ ุงูููุฏูุฉ ุงูููุฌูุฏุฉ. ููุนู ุงูุฅุตูุงุญ ุงูุดูุก ููุณูุ ููููู ูุญูู ููุท ููุทูุฉ ุงูุตูุฑุฉ ุงูุชู ุญุฏุฏูุง ุงูููุงุน ููุธู ุจุงูู ุงูุตูุฑุฉ ุฏูู ุชุบููุฑ. ููููู ุงุนุชุจุงุฑ ุงูุฅุตูุงุญ ูุฃุฏุงุฉ ุฃูุซุฑ ุฏูุฉ ูุฅุฌุฑุงุก ุชุบููุฑุงุช ูุญุฏุฏุฉ ูููุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ูุทุงู ุฃูุณุน ูุฅุฌุฑุงุก ุชุบููุฑุงุช ูุงุณุนุฉ ุงููุทุงู.


## ุงูุชุญูู ูู ุฅูุดุงุก ุงูุตูุฑ

ูู ุงูุตุนุจ ุฌุนู ุงูุตูุฑุฉ ุชุจุฏู ุจุงูุถุจุท ููุง ุชุฑูุฏ ูุฃู ุนูููุฉ ุฅุฒุงูุฉ ุงูุชุดููุด ุนุดูุงุฆูุฉ. ูู ุญูู ุฃูู ููููู ุงูุชุญูู ูู ุฌูุงูุจ ูุนููุฉ ูู ุงูุชูููุฏ ุนู ุทุฑูู ุชูููู ูุนููุงุช ูุซู "negative_prompt"ุ ููุงู ุทุฑู ุฃูุถู ูุฃูุซุฑ ููุงุกุฉ ููุชุญูู ูู ุฅูุดุงุก ุงูุตูุฑ.

### ูุฒู ุงููุญุต

ูููุฑ ูุฒู ุงููุญุต ุทุฑููุฉ ูุงุจูุฉ ููููุงุณ ุงูููู ูููุงุณ ุญุฌู ุชูุซูู ุงูููุงููู ูู ูุญุต. ููููู ุงุณุชุฎุฏุงูู ูุฒูุงุฏุฉ ุฃู ุชูููู ุญุฌู ูุชุฌู ุชุถููู ุงููุต ููู ููููู ูู ุงููุญุตุ ูุงูุฐู ูุญุฏุฏ ุจุนุฏ ุฐูู ููุฏุงุฑ ูู ููููู ูุชู ุชูููุฏู. ุชููุฑ ููุชุจุฉ [Compel](https://github.com/damian0815/compel) ุจูุงุก ุฌููุฉ ุจุฏููู ูููุงุณ ุฃูุฒุงู ุงููุญุต ูุชูููุฏ ุงูุชุถูููุงุช. ุชุนุฑู ุนูู ููููุฉ ุฅูุดุงุก ุงูุชุถูููุงุช ูู ุฏููู [ูุฒู ุงููุญุต](../using-diffusers/weighted_prompts).

ุจูุฌุฑุฏ ุฅูุดุงุก ุงูุชุถูููุงุชุ ูู ุจุชูุฑูุฑูุง ุฅูู ูุนููุฉ "prompt_embeds" (ู"negative_prompt_embeds" ุฅุฐุง ููุช ุชุณุชุฎุฏู ูุญุตูุง ุณูุจููุง) ูู ["AutoPipelineForInpainting"]. ุชุญู ุงูุชุถูููุงุช ูุญู ูุนููุฉ "ุงููุญุต":

```py
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16,
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt_embeds=prompt_embeds, # generated from Compel
    negative_prompt_embeds=negative_prompt_embeds, # generated from Compel
    image=init_image,
    mask_image=mask_image
).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```



### ControlNet

ุชูุณุชุฎุฏู ููุงุฐุฌ ControlNet ูุน ููุงุฐุฌ ุงูุงูุชุดุงุฑ ุงูุฃุฎุฑู ูุซู Stable Diffusionุ ูุชููุฑ ุทุฑููุฉ ุฃูุซุฑ ูุฑููุฉ ูุฏูุฉ ููุชุญูู ูู ููููุฉ ุฅูุดุงุก ุงูุตูุฑุฉ. ุชูุจู ControlNet ุฅุฏุฎุงู ุตูุฑุฉ ุชูููู ุฅุถุงููุฉ ุชูุฌู ูููุฐุฌ ุงูุงูุชุดุงุฑ ููุญูุงุธ ุนูู ุงูููุฒุงุช ุงูููุฌูุฏุฉ ูููุง.

ุนูู ุณุจูู ุงููุซุงูุ ุฏุนูุง ูููููู ุตูุฑุฉ ุจุงุณุชุฎุฏุงู ControlNet ููุฏุฑุจุฉ ูุณุจููุง ุนูู ุตูุฑ Inpaint:

```py
import torch
import numpy as np
from diffusers import ControlNetModel, StableDiffusionControlNetInpaintPipeline
from diffusers.utils import load_image, make_image_grid

# load ControlNet
controlnet = ControlNetModel.from_pretrained("lllyasviel/control_v11p_sd15_inpaint", torch_dtype=torch.float16, variant="fp16")

# pass ControlNet to the pipeline
pipeline = StableDiffusionControlNetInpaintPipeline.from_pretrained(
    "runwayml/stable-diffusion-inpainting", controlnet=controlnet, torch_dtype=torch.float16, variant="fp16"
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png")

# prepare control image
def make_inpaint_condition(init_image, mask_image):
    init_image = np.array(init_image.convert("RGB")).astype(np.float32) / 255.0
    mask_image = np.array(mask_image.convert("L")).astype(np.float32) / 255.0

    assert init_image.shape[0:1] == mask_image.shape[0:1], "image and image_mask must have the same image size"
    init_image[mask_image > 0.5] = -1.0  # set as masked pixel
    init_image = np.expand_dims(init_image, 0).transpose(0, 3, 1, 2)
    init_image = torch.from_numpy(init_image)
    return init_image

control_image = make_inpaint_condition(init_image, mask_image)
```

ุงูุขูุ ูู ุจุชูููุฏ ุตูุฑุฉ ูู ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉ ูุตูุฑุฉ ุงูููุงุน ูุตูุฑุฉ ุงูุชุญูู. ุณุชูุงุญุธ ุฃู ููุฒุงุช ุงูุตูุฑุฉ ุงูุฃุณุงุณูุฉ ูุญููุธุฉ ุจุดุฏุฉ ูู ุงูุตูุฑุฉ ุงููููุฏุฉ.

```py
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, control_image=control_image).images[0]
make_image_grid([init_image, mask_image, PIL.Image.fromarray(np.uint8(control_image[0][0])).convert('RGB'), image], rows=2, cols=2)
```

ููููู ุงููุถู ูุฏููุง ุฎุทูุฉ ุฃุฎุฑู ูุณูุณูุฉ ูุน ุฎุท ุฃูุงุจูุจ ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ูุชุทุจูู ุฃุณููุจ ุฌุฏูุฏ:
```py
from diffusers import AutoPipelineForImage2Image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "nitrosocke/elden-ring-diffusion", torch_dtype=torch.float16,
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

prompt = "elden ring style castle" # include the token "elden ring style" in the prompt
negative_prompt = "bad architecture, deformed, disfigured, poor details"

image_elden_ring = pipeline(prompt, negative_prompt=negative_prompt, image=image).images[0]
make_image_grid([init_image, mask_image, image, image_elden_ring], rows=2, cols=2)
```

<div class="flex flex-row gap-4">
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">initial image</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-controlnet.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">ControlNet inpaint</figcaption>
  </div>
  <div class="flex-1">
    <img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-img2img.png"/>
    <figcaption class="mt-2 text-center text-sm text-gray-500">image-to-image</figcaption>
  </div>
</div>

## ุงูุชุญุณูู

ูุฏ ูููู ูู ุงูุตุนุจ ูุงูุจุทูุก ุชุดุบูู ููุงุฐุฌ ุงูุงูุชุดุงุฑ ุฅุฐุง ููุช ุชุนุงูู ูู ูููุฏ ุงูููุงุฑุฏุ ูููู ููููู ุงุณุชุฎุฏุงู ุจุนุถ ุงูุญูู ุงูุชุญุณูููุฉ. ุฃุญุฏ ุฃูุจุฑ ุงูุชุญุณููุงุช (ูุฃุณูููุง) ุงูุชู ููููู ุชูููููุง ูู ุงูุชุจุฏูู ุฅูู ุงูุงูุชุจุงู ุงูููุก ููุฐุงูุฑุฉ. ุฅุฐุง ููุช ุชุณุชุฎุฏู PyTorch 2.0ุ ูุชู ุชูููู ุงูุงูุชุจุงู ูููุงุท ุงูููุชุฌ ุงููููููุฒ ุชููุงุฆููุงุ ููุง ููุฒู ุงูููุงู ุจุฃู ุดูุก ุขุฎุฑ. ุจุงููุณุจุฉ ููุณุชุฎุฏูู PyTorch ุบูุฑ 2.0ุ ููููู ุชุซุจูุช ูุงุณุชุฎุฏุงู ุชูููุฐ xFormers ููุงูุชูุงู ุงูููุก ููุฐุงูุฑุฉ. ููุง ุงูุฎูุงุฑูู ููููุงู ูู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ ูููุณุฑุนุงู ุงูุงุณุชุฏูุงู.

ููููู ุฃูุถูุง ููู ุงููููุฐุฌ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ ูุชูููุฑ ุงููุฒูุฏ ูู ุงูุฐุงูุฑุฉ:

```diff
+ pipeline.enable_xformers_memory_efficient_attention()
+ pipeline.enable_model_cpu_offload()
```


ูุฒูุงุฏุฉ ุชุณุฑูุน ุฑูุฒ ุงูุงุณุชุฏูุงู ุงูุฎุงุต ุจูุ ุงุณุชุฎุฏู [torch_compile](../optimization/torch2.0#torchcompile). ูุฌุจ ุนููู ูู [torch.compile](https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile) ุญูู ุงููููู ุงูุฃูุซุฑ ูุซุงูุฉ ูู ุงูุงุณุชุฎุฏุงู ูู ุฎุท ุงูุฃูุงุจูุจ ูุงูุฐู ูููู ุนุงุฏุฉู UNet:

```py
pipeline.unet = torch.compile(pipeline.unet, mode="reduce-overhead", fullgraph=True)
```

ุชุนุฑู ุนูู ุงููุฒูุฏ ูู ุฃุฏูุฉ [ุชูููู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ](../optimization/memory) ู [Torch 2.0](../optimization/torch2.0).