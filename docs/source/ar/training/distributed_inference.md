# ุงูุงุณุชูุชุงุฌ ุงูููุฒุน ูุน ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPUs) ูุชุนุฏุฏุฉ

ูู ุงูุฅุนุฏุงุฏุงุช ุงูููุฒุนุฉุ ููููู ุชุดุบูู ุงูุงุณุชูุชุงุฌ ุนุจุฑ ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุชุนุฏุฏุฉ ุจุงุณุชุฎุฏุงู [Accelerate](https://huggingface.co/docs/accelerate/index) ุฃู [PyTorch Distributed](https://pytorch.org/tutorials/beginner/dist_overview.html) ูู ๐คุ ููู ูููุฏ ูุฅูุดุงุก ููุฌูุงุช ูุชุนุฏุฏุฉ ุจุงูุชูุงุฒู.

ุณููุถุญ ูุฐุง ุงูุฏููู ููููุฉ ุงุณุชุฎุฏุงู ๐ค Accelerate ู PyTorch Distributed ููุงุณุชูุชุงุฌ ุงูููุฒุน.

## ๐ค Accelerate

๐ค [Accelerate](https://huggingface.co/docs/accelerate/index) ูู ููุชุจุฉ ูุตููุฉ ูุชุณููู ุงูุชุฏุฑูุจ ุฃู ุชุดุบูู ุงูุงุณุชุฏูุงู ุนุจุฑ ุงูุฅุนุฏุงุฏุงุช ุงูููุฒุนุฉ. ููู ูุจุณุท ุนูููุฉ ุฅุนุฏุงุฏ ุงูุจูุฆุฉ ุงูููุฒุนุฉุ ููุง ูุชูุญ ูู ุงูุชุฑููุฒ ุนูู ุฑูุฒ PyTorch ุงูุฎุงุต ุจู.

ููุจุฏุกุ ูู ุจุฅูุดุงุก ููู Python ููู ุจุชููุฆุฉ [`accelerate.PartialState`] ูุฅูุดุงุก ุจูุฆุฉ ููุฒุนุฉุ ูุชู ุงูุชุดุงู ุฅุนุฏุงุฏู ุชููุงุฆููุงุ ูุฐูู ูุง ุชุญุชุงุฌ ุฅูู ุชุญุฏูุฏ `rank` ุฃู `world_size` ุจุดูู ุตุฑูุญ. ูู ุจููู [`DiffusionPipeline`] ุฅูู `distributed_state.device` ูุชุนููู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ููู ุนูููุฉ.

ุงูุขู ุงุณุชุฎุฏู ุฃุฏุงุฉ [`~accelerate.PartialState.split_between_processes`] ุงููุณุงุนุฏุฉ ููุฏูุฑ ุณูุงู ูุชูุฒูุน ุงูููุฌูุงุช ุชููุงุฆููุง ุจูู ุนุฏุฏ ุงูุนูููุงุช.

```py
import torch
from accelerate import PartialState
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
)
distributed_state = PartialState()
pipeline.to(distributed_state.device)

with distributed_state.split_between_processes(["a dog", "a cat"]) as prompt:
    result = pipeline(prompt).images[0]
    result.save(f"result_{distributed_state.process_index}.png")
```

ุงุณุชุฎุฏู ุงูุญุฌุฉ `--num_processes` ูุชุญุฏูุฏ ุนุฏุฏ ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงูุชู ุณูุชู ุงุณุชุฎุฏุงููุงุ ูุงุณุชุฏุนู `accelerate launch` ูุชุดุบูู ุงูุจุฑูุงูุฌ ุงููุตู:

```bash
accelerate launch run_distributed.py --num_processes=2
```

<Tip>

ููุนุฑูุฉ ุงููุฒูุฏุ ุฑุงุฌุน ุฏููู [ุงูุงุณุชุฏูุงู ุงูููุฒุน ุจุงุณุชุฎุฏุงู ๐ค Accelerate](https://huggingface.co/docs/accelerate/en/usage_guides/distributed_inference#distributed-inference-with-accelerate).

</Tip>

### ูุถุน ุงูุฌูุงุฒ

> [!WARNING]
> ูุฐู ุงูููุฒุฉ ุชุฌุฑูุจูุฉ ููุฏ ุชุชุบูุฑ ูุงุฌูุงุช ุจุฑูุฌุฉ ุงูุชุทุจููุงุช ุงูุฎุงุตุฉ ุจูุง ูู ุงููุณุชูุจู.

ูุน Accelerateุ ููููู ุงุณุชุฎุฏุงู `device_map` ูุชุญุฏูุฏ ููููุฉ ุชูุฒูุน ููุงุฐุฌ ุฎุท ุงูุฃูุงุจูุจ ุนุจุฑ ุฃุฌูุฒุฉ ูุชุนุฏุฏุฉ. ูุฐุง ูููุฏ ูู ุงูุญุงูุงุช ุงูุชู ุชุญุชูู ุนูู ุฃูุซุฑ ูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุงุญุฏุฉ.

ุนูู ุณุจูู ุงููุซุงูุ ุฅุฐุง ูุงู ูุฏูู ูุญุฏุชู ูุนุงูุฌุฉ ุฑุณูููุงุช (GPU) ุจุณุนุฉ 8 ุฌูุฌุงุจุงูุชุ ููุฏ ูุง ูุนูู ุงุณุชุฎุฏุงู [`~DiffusionPipeline.enable_model_cpu_offload`] ุจุดูู ุฌูุฏ ูุฃูู:

- ูุนูู ููุท ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุงุญุฏุฉ
- ูุฏ ูุง ููุงุณุจ ูููุฐุฌ ูุงุญุฏ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุงุญุฏุฉ (ูุฏ ูุนูู [`~DiffusionPipeline.enable_sequential_cpu_offload`] ููููู ุณูููู ุจุทูุฆูุง ููุบุงูุฉ ููู ุฃูุถูุง ูุญุฏูุฏ ุจูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุงุญุฏุฉ)

ูุงุณุชุฎุฏุงู ูุญุฏุชู ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU)ุ ููููู ุงุณุชุฎุฏุงู ุฅุณุชุฑุงุชูุฌูุฉ ูุถุน ุงูุฌูุงุฒ "ุงููุชูุงุฒูุฉ" ุงูุชู ุชููู ุจุชูุณูู ุงูููุงุฐุฌ ุนุจุฑ ุฌููุน ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงููุชุงุญุฉ.

> [!WARNING]
> ูุชู ุฏุนู ุฅุณุชุฑุงุชูุฌูุฉ "ุงููุชูุงุฒูุฉ" ููุท ูู ุงูููุช ุงูุญุงููุ ููุฎุทุท ูุฏุนู ุฎุฑุงุฆุท ุฅุถุงููุฉ ูู ุงููุณุชูุจู.

```diff
from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained(
-    "runwayml/stable-diffusion-v1-5"ุ torch_dtype=torch.float16ุ use_safetensors=Trueุ
+    "runwayml/stable-diffusion-v1-5"ุ torch_dtype=torch.float16ุ use_safetensors=Trueุ device_map="balanced"
)
image = pipeline ("a dog").images [0]
image
```

ููููู ุฃูุถูุง ุชูุฑูุฑ ูุงููุณ ููุฑุถ ุงูุญุฏ ุงูุฃูุตู ูุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงูุชู ูููู ุงุณุชุฎุฏุงููุง ุนูู ูู ุฌูุงุฒ:

```diff
from diffusers import DiffusionPipeline
import torch

max_memory = {0:"1GB"ุ 1:"1GB"}
pipeline = DiffusionPipeline.from_pretrained(
"runwayml/stable-diffusion-v1-5"ุ
torch_dtype=torch.float16ุ
use_safetensors=Trueุ
device_map="balanced"ุ
+   max_memory=max_memory
)
image = pipeline ("a dog").images [0]
image
```

ุฅุฐุง ูู ููู ุงูุฌูุงุฒ ููุฌูุฏูุง ูู `max_memory`ุ ูุณูุชู ุชุฌุงููู ุชูุงููุง ููู ูุดุงุฑู ูู ูุถุน ุงูุฌูุงุฒ.

ุงูุชุฑุงุถููุงุ ูุณุชุฎุฏู Diffusers ุงูุญุฏ ุงูุฃูุตู ูุฐุงูุฑุฉ ุฌููุน ุงูุฃุฌูุฒุฉ. ุฅุฐุง ูู ุชูุงุณุจ ุงูููุงุฐุฌ ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU)ุ ูุณูุชู ููููุง ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU). ุฅุฐุง ูู ููู ูุฏู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ุฐุงูุฑุฉ ูุงููุฉุ ููุฏ ุชุฑู ุฎุทุฃู. ูู ูุฐู ุงูุญุงูุฉุ ููููู ุงููุฌูุก ุฅูู ุงุณุชุฎุฏุงู [`~DiffusionPipeline.enable_sequential_cpu_offload`] ู [`~DiffusionPipeline.enable_model_cpu_offload`].

ุงุชุตู [`~DiffusionPipeline.reset_device_map`] ูุฅุนุงุฏุฉ ุชุนููู `device_map` ูุฎุท ุงูุฃูุงุจูุจ. ูุฐุง ุถุฑูุฑู ุฃูุถูุง ุฅุฐุง ููุช ุชุฑูุฏ ุงุณุชุฎุฏุงู ุทุฑู ูุซู `to()`ุ [`~DiffusionPipeline.enable_sequential_cpu_offload`]ุ ู [`~DiffusionPipeline.enable_model_cpu_offload`] ุนูู ุฎุท ุฃูุงุจูุจ ุชู ุชุนููู ุฌูุงุฒู.

```py
pipeline.reset_device_map()
```

ุจูุฌุฑุฏ ุชุนููู ุฌูุงุฒ ุฎุท ุงูุฃูุงุจูุจุ ููููู ุฃูุถูุง ุงููุตูู ุฅูู ุฎุฑูุทุฉ ุงูุฌูุงุฒ ุงูุฎุงุตุฉ ุจู ุนุจุฑ `hf_device_map`:

```py
print(pipeline.hf_device_map)
```

ูุฏ ุชุจุฏู ุฎุฑูุทุฉ ุงูุฌูุงุฒ ุนูู ุงููุญู ุงูุชุงูู:

```bash
{"unet": 1ุ "vae": 1ุ "safety_checker": 0ุ "text_encoder": 0}
```

## PyTorch ุงูููุฒุน

ุชุฏุนู PyTorch [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html) ุงูุฐู ููููู ุงูููุงุฒุงุฉ ููุจูุงูุงุช.

ููุจุฏุกุ ูู ุจุฅูุดุงุก ููู Python ูุงุณุชูุฑุฏ `torch.distributed` ู `torch.multiprocessing` ูุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุนูููุงุช ุงูููุฒุนุฉ ููุฅูุดุงุก ุงูุนูููุงุช ููุงุณุชุฏูุงู ุนูู ูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU). ูุฌุจ ุนููู ุฃูุถูุง ุชููุฆุฉ [`DiffusionPipeline`]:

```py
import torch
import torch.distributed as dist
import torch.multiprocessing as mp

from diffusers import DiffusionPipeline

sd = DiffusionPipeline.from_pretrained(
"runwayml/stable-diffusion-v1-5"ุ torch_dtype=torch.float16ุ use_safetensors=True
)
```

ุณุชุญุชุงุฌ ุฅูู ุฅูุดุงุก ุฏุงูุฉ ูุชุดุบูู ุงูุงุณุชุฏูุงูุ [`init_process_group`](https://pytorch.org/docs/stable/distributed.html?highlight=init_process_group#torch.distributed.init_process_group) ูุชุนุงูู ูุน ุฅูุดุงุก ุจูุฆุฉ ููุฒุนุฉ ูุน ููุน backend ุงูุฐู ุณูุชู ุงุณุชุฎุฏุงููุ `rank` ููุนูููุฉ ุงูุญุงููุฉุ ู`world_size` ุฃู ุนุฏุฏ ุงูุนูููุงุช ุงููุดุงุฑูุฉ. ุฅุฐุง ููุช ุชููู ุจุชุดุบูู ุงูุงุณุชุฏูุงู ุจุงูุชูุงุฒู ุนูู ูุญุฏุชู ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU)ุ ูุฅู `world_size` ูู 2.

ูู ุจููู [`DiffusionPipeline`] ุฅูู `rank` ูุงุณุชุฎุฏู `get_rank` ูุชุนููู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ููู ุนูููุฉุ ุญูุซ ุชุชุนุงูู ูู ุนูููุฉ ูุน ููุฌู ูุฎุชูู:

```py
def run_inference(rank, world_size):
    dist.init_process_group("nccl", rank=rank, world_size=world_size)

    sd.to(rank)

    if torch.distributed.get_rank() == 0:
        prompt = "a dog"
    elif torch.distributed.get_rank() == 1:
        prompt = "a cat"

    image = sd(prompt).images[0]
    image.save(f"./{'_'.join(prompt)}.png")
```

ูุชุดุบูู ุงูุงุณุชุฏูุงู ุงูููุฒุนุ ุงุชุตู [`mp.spawn`](https://pytorch.org/docs/stable/multiprocessing.html#torch.multiprocessing.spawn) ูุชุดุบูู ุฏุงูุฉ `run_inference` ุนูู ุนุฏุฏ ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงููุญุฏุฏุฉ ูู `world_size`:

```py
def main():
world_size = 2
mp.spawn(run_inferenceุ args=(world_sizeุ)ุ nprocs=world_sizeุ join=True)


if __name__ == "__main__":
main()
```

ุจูุฌุฑุฏ ุงูุงูุชูุงุก ูู ูุชุงุจุฉ ูุต ุงูุงุณุชุฏูุงูุ ุงุณุชุฎุฏู ุงูุญุฌุฉ `--nproc_per_node` ูุชุญุฏูุฏ ุนุฏุฏ ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงูุชู ุณูุชู ุงุณุชุฎุฏุงููุง ูุงุณุชุฏุนุงุก `torchrun` ูุชุดุบูู ุงูุจุฑูุงูุฌ ุงููุตู:

```bash
torchrun run_distributed.py --nproc_per_node=2
```