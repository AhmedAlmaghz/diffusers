## ุชูููู ููุงุฐุฌ ุงูุงูุชุดุงุฑ 

ุชูููู ุงูููุงุฐุฌ ุงูุชูููุฏูุฉ ูุซู [Stable Diffusion](https://huggingface.co/docs/diffusers/stable_diffusion) ูู ุฃูุฑ ุฐุงุชู ุจุทุจูุนุชู. ูููู ูููุงุฑุณูู ูุจุงุญุซููุ ุบุงูุจุงู ูุง ูุชุนูู ุนูููุง ุงุชุฎุงุฐ ุฎูุงุฑุงุช ุฏูููุฉ ูู ุจูู ุงูุนุฏูุฏ ูู ุงูุงุญุชูุงูุงุช ุงููุฎุชููุฉ. ูุฐููุ ุนูุฏ ุงูุนูู ูุน ููุงุฐุฌ ุชูููุฏูุฉ ูุฎุชููุฉ (ูุซู GANs ู Diffusionุ ุฅูุฎ)ุ ููู ูุฎุชุงุฑ ุฃุญุฏูุง ุนูู ุงูุขุฎุฑุ

ูููู ุฃู ูููู ุงูุชูููู ุงูููุนู ููุซู ูุฐู ุงูููุงุฐุฌ ุนุฑุถุฉ ููุฃุฎุทุงุก ููุฏ ูุคุซุฑ ุจุดูู ุบูุฑ ุตุญูุญ ุนูู ุงููุฑุงุฑ. ููุน ุฐููุ ูุฅู ุงูููุงููุณ ุงููููุฉ ูุง ุชุชูุงูู ุจุงูุถุฑูุฑุฉ ูุน ุฌูุฏุฉ ุงูุตูุฑุฉ. ูุฐููุ ุนุงุฏุฉ ูุง ูููุฑ ูุฒูุฌ ูู ุงูุชููููุงุช ุงูููุนูุฉ ูุงููููุฉ ุฅุดุงุฑุฉ ุฃููู ุนูุฏ ุงุฎุชูุงุฑ ูููุฐุฌ ูุงุญุฏ ุนูู ุงูุขุฎุฑ.

ูู ูุฐู ุงููุซููุฉุ ููุฏู ูุธุฑุฉ ุนุงูุฉ ุบูุฑ ุดุงููุฉ ุนูู ุงูุฃุณุงููุจ ุงูููุนูุฉ ูุงููููุฉ ูุชูููู ููุงุฐุฌ ุงูุงูุชุดุงุฑ. ูุจุงููุณุจุฉ ููุฃุณุงููุจ ุงููููุฉุ ูุฑูุฒ ุจุดูู ุฎุงุต ุนูู ููููุฉ ุชูููุฐูุง ุฅูู ุฌุงูุจ `diffusers`.

ูููู ุฃูุถูุง ุงุณุชุฎุฏุงู ุงูุฃุณุงููุจ ุงูููุถุญุฉ ูู ูุฐู ุงููุซููุฉ ูุชูููู ูุฎุทุทุงุช ุงูุถูุถุงุก ุงููุฎุชููุฉ ูุน ุชุซุจูุช ูููุฐุฌ ุงูุชูููุฏ ุงูุฃุณุงุณู.

## ุงูุณููุงุฑูููุงุช

ูุบุทู ููุงุฐุฌ ุงูุงูุชุดุงุฑ ูุน ุฎุทูุท ุงูุฃูุงุจูุจ ุงูุชุงููุฉ:

- ุชูููุฏ ุงูุตูุฑ ุงูููุฌูุฉ ุจุงููุต (ูุซู [`StableDiffusionPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/text2img)).
- ุชูููุฏ ุงูุตูุฑ ุงูููุฌูุฉ ุจุงููุตุ ุงููุดุฑูุทุฉ ุฃูุถูุง ุจุตูุฑุฉ ุงููุฏุฎูุงุช (ูุซู [`StableDiffusionImg2ImgPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/img2img) ู [`StableDiffusionInstructPix2PixPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/pix2pix)).
- ููุงุฐุฌ ุชูููุฏ ุงูุตูุฑ ุงููุดุฑูุทุฉ ุจุงููุตู (ูุซู [`DiTPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/dit)).

## ุงูุชูููู ุงูููุนู

ููุทูู ุงูุชูููู ุงูููุนู ุนุงุฏุฉ ุนูู ุชูููู ุจุดุฑู ููุตูุฑ ุงููููุฏุฉ. ูุชููุงุณ ุงูุฌูุฏุฉ ุนุจุฑ ุฌูุงูุจ ูุซู ุงูุชููููุ ูุงููุญุงุฐุงุฉ ุจูู ุงูุตูุฑุฉ ูุงููุตุ ูุงูุนูุงูุงุช ุงูููุงููุฉ. ุชููุฑ ุงููุทุงูุจุงุช ุงูุดุงุฆุนุฉ ุฏุฑุฌุฉ ูู ุงูุชูุญูุฏ ููููุงููุณ ุงูุฐุงุชูุฉ.

DrawBench ู PartiPrompts ูู ูุฌููุนุงุช ุจูุงูุงุช ุงููุทุงูุจุฉ ุงููุณุชุฎุฏูุฉ ููููุงุฑูุฉ ุงููุฑุฌุนูุฉ ุงูููุนูุฉ. ุชู ุชูุฏูู DrawBench ู PartiPrompts ุจูุงุณุทุฉ [Imagen](https://imagen.research.google/) ู [Parti](https://parti.research.google/) ุนูู ุงูุชูุงูู.

ูู [ุงููููุน ุงูุฑุณูู ูู Parti](https://parti.research.google/):

> PartiPrompts (P2) ูู ูุฌููุนุฉ ุบููุฉ ุชุถู ุฃูุซุฑ ูู 1600 ูุทุงูุจุฉ ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ ูููู ุจุฅุตุฏุงุฑูุง ูุฌุฒุก ูู ูุฐุง ุงูุนูู. ูููู ุงุณุชุฎุฏุงู P2 ูููุงุณ ูุฏุฑุงุช ุงููููุฐุฌ ุนุจุฑ ูุฎุชูู ุงููุฆุงุช ูุชุญุฏูุงุช ุงูุฌูุงูุจ.

![parti-prompts](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/parti-prompts.png)

ูุญุชูู PartiPrompts ุนูู ุงูุฃุนูุฏุฉ ุงูุชุงููุฉ:

- ูุทุงูุจุฉ
- ูุฆุฉ ุงููุทุงูุจุฉ (ูุซู "ูุฌุฑุฏุฉ"ุ "ูุนุฑูุฉ ุงูุนุงูู"ุ ุฅูุฎ)
- ุงูุชุญุฏู ุงูุฐู ูุนูุณ ุงูุตุนูุจุฉ (ูุซู "ุฃุณุงุณู"ุ "ูุนูุฏ"ุ "ุงููุชุงุจุฉ ูุงูุฑููุฒ"ุ ุฅูุฎ)

ุชุณูุญ ูุฐู ุงููุนุงููุฑ ุงููุฑุฌุนูุฉ ุจุงูุชูููู ุงูุจุดุฑู ุฌูุจูุง ุฅูู ุฌูุจ ูููุงุฐุฌ ุชูููุฏ ุงูุตูุฑ ุงููุฎุชููุฉ.

ููุฐุงุ ูุงู ูุฑูู ๐งจ Diffusers ุจุจูุงุก **Open Parti Prompts**ุ ููู ูุนูุงุฑ ูุฑุฌุนู ููุนู ูุฏููุน ุจุงููุฌุชูุน ูุนุชูุฏ ุนูู Parti Prompts ูููุงุฑูุฉ ุฃุญุฏุซ ููุงุฐุฌ ุงูุงูุชุดุงุฑ ููุชูุญุฉ ุงููุตุฏุฑ:

- [Open Parti Prompts Game](https://huggingface.co/spaces/OpenGenAI/open-parti-prompts): ูุนุดุฑุฉ ูุทุงูุจุงุช ูู Partiุ ูุชู ุนุฑุถ ุฃุฑุจุน ุตูุฑุ ููุฎุชุงุฑ ุงููุณุชุฎุฏู ุงูุตูุฑุฉ ุงูุชู ุชูุงุณุจ ุงููุทุงูุจุฉ ุจุดูู ุฃูุถู.
- [Open Parti Prompts Leaderboard](https://huggingface.co/spaces/OpenGenAI/parti-prompts-leaderboard): ููุญุฉ ุงูููุงุฏุฉ ุงูุชู ุชูุงุฑู ุฃูุถู ููุงุฐุฌ ุงูุงูุชุดุงุฑ ููุชูุญุฉ ุงููุตุฏุฑ ูู ุงูููุช ุงูุญุงูู ุจุจุนุถูุง ุงูุจุนุถ.

ูููุงุฑูุฉ ุงูุตูุฑ ูุฏูููุงุ ุฏุนูุง ูุฑู ููู ูููููุง ุงุณุชุฎุฏุงู `diffusers` ุนูู ุจุนุถ PartiPrompts.

ูููุง ููู ุจุนุถ ุงููุทุงูุจุงุช ุงูุชู ุชู ุฃุฎุฐ ุนููุงุช ูููุง ุนุจุฑ ุชุญุฏูุงุช ูุฎุชููุฉ: Basic ู Complex ู Linguistic Structures ู Imagination ู Writing & Symbols. ููุง ูุณุชุฎุฏู PartiPrompts ูู [ูุฌููุนุฉ ุจูุงูุงุช](https://huggingface.co/datasets/nateraw/parti-prompts).

```python
from datasets import load_dataset

# prompts = load_dataset("nateraw/parti-prompts", split="train")
# prompts = prompts.shuffle()
# sample_prompts = [prompts[i]["Prompt"] for i in range(5)]

# ุชุซุจูุช ูุฐู ุงููุทุงูุจุงุช ุงูุชูุถูุญูุฉ ูุตุงูุญ ุงููุงุจููุฉ ููุชูุฑุงุฑ.
sample_prompts = [
"a corgi",
"a hot air balloon with a yin-yang symbol, with the moon visible in the daytime sky",
"a car with no windows",
"a cube made of porcupine",
'The saying "BE EXCELLENT TO EACH OTHER" written on a red brick wall with a graffiti image of a green alien wearing a tuxedo. A yellow fire hydrant is on a sidewalk in the foreground.',
]
```

ุงูุขู ูููููุง ุงุณุชุฎุฏุงู ูุฐู ุงููุทุงูุจุงุช ูุชูููุฏ ุจุนุถ ุงูุตูุฑ ุจุงุณุชุฎุฏุงู Stable Diffusion ([v1-4 checkpoint](https://huggingface.co/CompVis/stable-diffusion-v1-4)):

```python
import torch

seed = 0
generator = torch.manual_seed(seed)

images = sd_pipeline(sample_prompts, num_images_per_prompt=1, generator=generator).images
```

![parti-prompts-14](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/parti-prompts-14.png)

ูููููุง ุฃูุถูุง ุชุนููู `num_images_per_prompt` ููููุง ูุฐูู ูููุงุฑูุฉ ุตูุฑ ูุฎุชููุฉ ูููุณ ุงููุทุงูุจุฉ. ูุคุฏู ุชุดุบูู ููุณ ุฎุท ุงูุฃูุงุจูุจ ูููู ูุน ููุทุฉ ูุฑุฌุนูุฉ ูุฎุชููุฉ ([v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)) ุฅูู ูุง ููู:

![parti-prompts-15](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/parti-prompts-15.png)

ุจูุฌุฑุฏ ุชูููุฏ ุนุฏุฉ ุตูุฑ ูู ุฌููุน ุงููุทุงูุจุงุช ุจุงุณุชุฎุฏุงู ููุงุฐุฌ ูุชุนุฏุฏุฉ (ููุฏ ุงูุชูููู)ุ ูุชู ุชูุฏูู ูุฐู ุงููุชุงุฆุฌ ุฅูู ูููููู ุจุดุฑููู ููุชุตููู. ููุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ูุนุงููุฑ DrawBench ู PartiPrompts ุงููุฑุฌุนูุฉุ ูุฑุฌู ุงูุฑุฌูุน ุฅูู ุฃูุฑุงููู ุงูุจุญุซูุฉ.

<Tip>
ูู ุงููููุฏ ุงููุธุฑ ูู ุจุนุถ ุนููุงุช ุงูุงุณุชุฏูุงู ุฃุซูุงุก ุชุฏุฑูุจ ุงููููุฐุฌ ูููุงุณ ุงูุชูุฏู ุงููุญุฑุฒ ูู ุงูุชุฏุฑูุจ. ูู [ุณูุฑูุจุชุงุช ุงูุชุฏุฑูุจ](https://github.com/huggingface/diffusers/tree/main/examples/) ุงูุฎุงุตุฉ ุจูุงุ ูุฏุนู ูุฐู ุงูุฃุฏุงุฉ ุงููุธูููุฉ ูุน ุฏุนู ุฅุถุงูู ููุชุณุฌูู ูู TensorBoard ู Weights & Biases.
</Tip>

## ุงูุชูููู ุงูููู

ูู ูุฐุง ุงููุณูุ ุณูููู ุจุฅุฑุดุงุฏู ุฎูุงู ุนูููุฉ ุชูููู ุซูุงุซ ุฎุทูุท ุฃูุงุจูุจ ุงูุชุดุงุฑ ูุฎุชููุฉ ุจุงุณุชุฎุฏุงู:

- ูุชูุฌุฉ CLIP
- ุงูุชุดุงุจู ุงูุงุชุฌุงูู CLIP
- FID

### ุชูููุฏ ุงูุตูุฑ ุงูููุฌูุฉ ุจุงููุต

[ูุชูุฌุฉ CLIP](https://arxiv.org/abs/2104.08718) ุชููุณ ุชูุงูู ุฃุฒูุงุฌ ุงูุตูุฑ ูุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ. ุชุดูุฑ ุงูุฏุฑุฌุงุช ุงูุฃุนูู ููุชูุฌุฉ CLIP ุฅูู ุชูุงูู ุฃุนูู ๐ผ. ูุชูุฌุฉ CLIP ูู ููุงุณ ููู ููููููู ุงูููุนู "ุงูุชูุงูู". ูููู ุฃูุถูุง ุงุนุชุจุงุฑ ุชูุงูู ุฃุฒูุงุฌ ุงูุตูุฑ ูุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ุนูู ุฃูู ุงูุชุดุงุจู ุงูุฏูุงูู ุจูู ุงูุตูุฑุฉ ูุงูุชุนููู ุงูุชูุถูุญู. ููุฏ ูุฌุฏ ุฃู ูุชูุฌุฉ CLIP ููุง ุนูุงูุฉ ูููุฉ ุจุงูุญูู ุงูุจุดุฑู.

ูู ุฃููุงู ุจุชุญููู [`StableDiffusionPipeline`]:

```python
from diffusers import StableDiffusionPipeline
import torch

model_ckpt = "CompVis/stable-diffusion-v1-4"
sd_pipeline = StableDiffusionPipeline.from_pretrained(model_ckpt, torch_dtype=torch.float16).to("cuda")
```

ูู ุจุชูููุฏ ุจุนุถ ุงูุตูุฑ ูุน ูุทุงูุจุงุช ูุชุนุฏุฏุฉ:

```python
prompts = [
"a photo of an astronaut riding a horse on mars",
"A high tech solarpunk utopia in the Amazon rainforest",
"A pikachu fine dining with a view to the Eiffel Tower",
"A mecha robot in a favela in expressionist style",
"an insect robot preparing a delicious meal",
"A small cabin on top of a snowy mountain in the style of Disney, artstation",
]

images = sd_pipeline(prompts, num_images_per_prompt=1, output_type="np").images

print(images.shape)
# (6, 512, 512, 3)
```

ุจุนุฏ ุฐููุ ูููู ุจุญุณุงุจ ูุชูุฌุฉ CLIP.

```python
from torchmetrics.functional.multimodal import clip_score
from functools import partial

clip_score_fn = partial(clip_score, model_name_or_path="openai/clip-vit-base-patch16")

def calculate_clip_score(images, prompts):
images_int = (images * 255).astype("uint8")
clip_score = clip_score_fn(torch.from_numpy(images_int).permute(0, 3, 1, 2), prompts).detach()
return round(float(clip_score), 4)

sd_clip_score = calculate_clip_score(images, prompts)
print(f"CLIP score: {sd_clip_score}")
# ูุชูุฌุฉ CLIP: 35.7038
```

ูู ุงููุซุงู ุฃุนูุงูุ ูููุง ุจุชูููุฏ ุตูุฑุฉ ูุงุญุฏุฉ ููู ูุทุงูุจุฉ. ุฅุฐุง ูููุง ุจุชูููุฏ ุตูุฑ ูุชุนุฏุฏุฉ ููู ูุทุงูุจุฉุ ูุณูู ูุถุทุฑ ุฅูู ุฃุฎุฐ ูุชูุณุท ุงูุฏุฑุฌุงุช ูู ุงูุตูุฑ ุงููููุฏุฉ ููู ูุทุงูุจุฉ.

ุงูุขูุ ุฅุฐุง ุฃุฑุฏูุง ููุงุฑูุฉ ููุทุชู ูุฑุงูุจุฉ ูุชูุงููุชูู ูุน [`StableDiffusionPipeline`]ุ ููุฌุจ ุนูููุง ุชูุฑูุฑ ูููุฏ ุฃุซูุงุก ุงุณุชุฏุนุงุก ุฎุท ุงูุฃูุงุจูุจ. ุฃููุงูุ ูููู ุจุชูููุฏ ุงูุตูุฑ ุจุงุณุชุฎุฏุงู ุจุฐุฑุฉ ุซุงุจุชุฉ ูุน [ููุทุฉ ูุฑุฌุนูุฉ ูุณุชูุฑุฉ ููุงูุชุดุงุฑ v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4):

```python
seed = 0
generator = torch.manual_seed(seed)

images = sd_pipeline(prompts, num_images_per_prompt=1, generator=generator, output_type="np").images
```

ุจุนุฏ ุฐููุ ูููู ุจุชุญููู ููุทุฉ ูุฑุฌุนูุฉ [v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) ูุชูููุฏ ุงูุตูุฑ:

```python
model_ckpt_1_5 = "runwayml/stable-diffusion-v1-5"
sd_pipeline_1_5 = StableDiffusionPipeline.from_pretrained(model_ckpt_1_5, torch_dtype=weight_dtype).to(device)

images_1_5 = sd_pipeline_1_5(prompts, num_images_per_prompt=1, generator=generator, output_type="np").images
```

ูุฃุฎูุฑูุงุ ููุงุฑู ูุชุงุฆุฌ CLIP ุงูุฎุงุตุฉ ุจูู:

```python
sd_clip_score_1_4 = calculate_clip_score(images, prompts)
print(f"ูุชูุฌุฉ CLIP ูุน v-1-4: {sd_clip_score_1_4}")
# ูุชูุฌุฉ CLIP ูุน v-1-4: 34.9102

sd_clip_score_1_5 = calculate_clip_score(images_1_5, prompts)
print(f"ูุชูุฌุฉ CLIP ูุน v-1-5: {sd_clip_score_1_5}")
# ูุชูุฌุฉ CLIP ูุน v-1-5: 36.2137
```

ูุจุฏู ุฃู ููุทุฉ ูุฑุฌุนูุฉ [v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) ุชุคุฏู ุฃุฏุงุกู ุฃูุถู ูู ุณุงุจูุชูุง. ููุน ุฐููุ ูุงุญุธ ุฃู ุนุฏุฏ ุงููุทุงูุจุงุช ุงูุชู ุงุณุชุฎุฏููุงูุง ูุญุณุงุจ ูุชุงุฆุฌ CLIP ููุฎูุถุฉ ุฌุฏูุง. ูู ุฃุฌู ุชูููู ุฃูุซุฑ ุนูููุฉุ ูุฌุจ ุฃู ูููู ูุฐุง ุงูุฑูู ุฃุนูู ุจูุซูุฑุ ููุฌุจ ุฃู ุชููู ุงููุทุงูุจุงุช ูุชููุนุฉ.

<Tip warning={true}>
ุจุญูู ุงูุจูุงุกุ ููุงู ุจุนุถ ุงููููุฏ ูู ูุฐู ุงููุชูุฌุฉ. ูุงูุช ุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุชุฏุฑูุจูุฉ
ุชู ุงูุญุตูู ุนูููุง ูู ุงูููุจ ูุชู ุงุณุชุฎุฑุงุฌูุง ูู ุงูุนูุงูุงุช `alt` ูุงูุนูุงูุงุช ุงูููุงุซูุฉ ุงููุฑุชุจุทุฉ ุจุตูุฑุฉ ุนูู ุงูุฅูุชุฑูุช.
ูุฏ ูุง ุชููู ููุซูุฉ ุจุงูุถุฑูุฑุฉ ููุง ูุฏ ูุณุชุฎุฏูู ุงูุฅูุณุงู ููุตู ุตูุฑุฉ. ูุจุงูุชุงููุ ูุงู ุนูููุง "ููุฏุณุฉ" ุจุนุถ ุงููุทุงูุจุงุช ููุง.
</Tip>
### ุชูููุฏ ุงูุตูุฑ ุงููุดุฑูุทุฉ ุจุงูุตูุฑ ูุงููุตูุต

ูู ูุฐู ุงูุญุงูุฉุ ูููู ุจุถุจุท ุฎุท ุฃูุงุจูุจ ุงูุชูููุฏ ุจุงุณุชุฎุฏุงู ุตูุฑุฉ ุฅุฏุฎุงู ุจุงูุฅุถุงูุฉ ุฅูู ููุฌู ูุตู. ุฏุนูุง ูุฃุฎุฐ [`StableDiffusionInstructPix2PixPipeline`] ููุซุงู. ููู ูุฃุฎุฐ ุชุนูููุงุช ุชุนุฏูู ูุฅุฏุฎุงู ููุฌู ูุตูุฑุฉ ุฅุฏุฎุงู ููุชู ุชุนุฏูููุง.

ูุฐุง ูุซุงู ุนูู ุฐูู:

![ุชุนูููุงุช ุงูุชุนุฏูู](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/edit-instruction.png)

ุชุชูุซู ุฅุญุฏู ุงูุงุณุชุฑุงุชูุฌูุงุช ูุชูููู ูุซู ูุฐุง ุงููููุฐุฌ ูู ููุงุณ ุงุชุณุงู ุงูุชุบููุฑ ุจูู ุงูุตูุฑุชูู (ูู ูุณุงุญุฉ CLIP) ูุน ุงูุชุบููุฑ ุจูู ุชุนูููู ุงูุตูุฑุชูู (ููุง ูู ููุถุญ ูู "ุชูููู ุงููุฌุงู ุงูููุฌู ุจู CLIP ููููุฏุงุช ุงูุตูุฑ"). ูุดุงุฑ ุฅูู ุฐูู ุจุงุณู "**ุชุดุงุจู ุงูุงุชุฌุงู CLIP**".

- ูุชูุงูู ุงูุนููุงู ุงููุฑุนู 1 ูุน ุตูุฑุฉ ุงูุฅุฏุฎุงู (ุงูุตูุฑุฉ 1) ุงูุชู ุณูุชู ุชุนุฏูููุง.
- ูุชูุงูู ุงูุนููุงู ุงููุฑุนู 2 ูุน ุงูุตูุฑุฉ ุงููุนุฏูุฉ (ุงูุตูุฑุฉ 2). ูุฌุจ ุฃู ูุนูุณ ุชุนูููุงุช ุงูุชุนุฏูู.

ูููุง ููู ูุธุฑุฉ ุนุงูุฉ ุชูุถูุญูุฉ:

![ุงุชุณุงู ุงูุชุนุฏูู](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/edit-consistency.png)

ููุฏ ุฃุนุฏุฏูุง ูุฌููุนุฉ ุจูุงูุงุช ูุตุบุฑุฉ ูุชูููุฐ ูุฐุง ุงููููุงุณ. ุฏุนูุง ุฃููุงู ูููู ุจุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช.

```python
from datasets import load_dataset

dataset = load_dataset("sayakpaul/instructpix2pix-demo", split="train")
dataset.features
```

```bash
{'input': Value(dtype='string', id=None),
'edit': Value(dtype='string', id=None),
'output': Value(dtype='string', id=None),
'image': Image(decode=True, id=None)}
```

ููุง ูุฏููุง:

- `input` ูู ุนููุงู ูุฑุนู ูุทุงุจู ูู `image`.
- ูุดูุฑ `edit` ุฅูู ุชุนูููุงุช ุงูุชุนุฏูู.
- ูุดูุฑ `output` ุฅูู ุงูุนููุงู ุงููุฑุนู ุงููุนุฏู ุงูุฐู ูุนูุณ ุชุนูููุงุช `edit`.

ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ุนููุฉ.

```python
idx = 0
print(f"Original caption: {dataset[idx]['input']}")
print(f"Edit instruction: {dataset[idx]['edit']}")
print(f"Modified caption: {dataset[idx]['output']}")
```

```bash
Original caption: 2. FAROE ISLANDS: An archipelago of 18 mountainous isles in the North Atlantic Ocean between Norway and Iceland, the Faroe Islands has 'everything you could hope for', according to Big 7 Travel. It boasts 'crystal clear waterfalls, rocky cliffs that seem to jut out of nowhere and velvety green hills'
Edit instruction: make the isles all white marble
Modified caption: 2. WHITE MARBLE ISLANDS: An archipelago of 18 mountainous white marble isles in the North Atlantic Ocean between Norway and Iceland, the White Marble Islands has 'everything you could hope for', according to Big 7 Travel. It boasts 'crystal clear waterfalls, rocky cliffs that seem to jut out of nowhere and velvety green hills'
```

ููุฐู ูู ุงูุตูุฑุฉ:

```python
dataset[idx]["image"]
```

![ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุนุฏูู](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/edit-dataset.png)

ุณูููู ุฃููุงู ุจุชุนุฏูู ุตูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจูุง ุจุงุณุชุฎุฏุงู ุชุนูููุงุช ุงูุชุนุฏูู ูุญุณุงุจ ุงูุชุดุงุจู ุงูุงุชุฌุงูู.

ุฏุนูุง ุฃููุงู ูููู ุจุชุญููู [`StableDiffusionInstructPix2PixPipeline`]:

```python
from diffusers import StableDiffusionInstructPix2PixPipeline

instruct_pix2pix_pipeline = StableDiffusionInstructPix2PixPipeline.from_pretrained(
"timbrooks/instruct-pix2pix", torch_dtype=torch.float16
).to(device)
```

ุงูุขูุ ูููู ุจุงูุชุนุฏููุงุช:

```python
import numpy as np


def edit_image(input_image, instruction):
    image = instruct_pix2pix_pipeline(
    instruction,
    image=input_image,
    output_type="np",
    generator=generator,
    ).images[0]
    return image

input_images = []
original_captions = []
modified_captions = []
edited_images = []

for idx in range(len(dataset)):
    input_image = dataset[idx]["image"]
    edit_instruction = dataset[idx]["edit"]
    edited_image = edit_image(input_image, edit_instruction)

    input_images.append(np.array(input_image))
    original_captions.append(dataset[idx]["input"])
    modified_captions.append(dataset[idx]["output"])
    edited_images.append(edited_image)
```

ูููุงุณ ุงูุชุดุงุจู ุงูุงุชุฌุงููุ ูููู ุฃููุงู ุจุชุญููู ุจุฑุงูุฌ ุงูุชุฑููุฒ ููุตูุฑ ูุงููุตูุต CLIP:

```python
from transformers import (
CLIPTokenizer,
CLIPTextModelWithProjection,
CLIPVisionModelWithProjection,
CLIPImageProcessor,
)

clip_id = "openai/clip-vit-large-patch14"
tokenizer = CLIPTokenizer.from_pretrained(clip_id)
text_encoder = CLIPTextModelWithProjection.from_pretrained(clip_id).to(device)
image_processor = CLIPImageProcessor.from_pretrained(clip_id)
image_encoder = CLIPVisionModelWithProjection.from_pretrained(clip_id).to(device)
```

ูุงุญุธ ุฃููุง ูุณุชุฎุฏู ููุทุฉ ุชูุชูุด CLIP ูุนููุฉุ ุฃู `openai/clip-vit-large-patch14`. ููุฑุฌุน ุฐูู ุฅูู ุฃู ุงูุชุฏุฑูุจ ุงููุณุจู ูู Stable Diffusion ุชู ุฅุฌุฑุงุคู ุจุงุณุชุฎุฏุงู ูุฐุง ุงููุชุบูุฑ ูู CLIP. ููุฒูุฏ ูู ุงูุชูุงุตููุ ูุฑุฌู ุงูุฑุฌูุน ุฅูู [ุงููุซุงุฆู](https://huggingface.co/docs/transformers/model_doc/clip).

ุจุนุฏ ุฐููุ ูููู ุจุฅุนุฏุงุฏ `nn.Module` ูู PyTorch ูุญุณุงุจ ุงูุชุดุงุจู ุงูุงุชุฌุงูู:

```python
import torch.nn as nn
import torch.nn.functional as F


class DirectionalSimilarity(nn.Module):
    def __init__(self, tokenizer, text_encoder, image_processor, image_encoder):
        super().__init__()
        self.tokenizer = tokenizer
        self.text_encoder = text_encoder
        self.image_processor = image_processor
        self.image_encoder = image_encoder

    def preprocess_image(self, image):
        image = self.image_processor(image, return_tensors="pt")["pixel_values"]
        return {"pixel_values": image.to(device)}

    def tokenize_text(self, text):
        inputs = self.tokenizer(
        text,
        max_length=self.tokenizer.model_max_length,
        padding="max_length",
        truncation=True,
        return_tensors="pt",
        )
        return {"input_ids": inputs.input_ids.to(device)}

    def encode_image(self, image):
        preprocessed_image = self.preprocess_image(image)
        image_features = self.image_encoder(**preprocessed_image).image_embeds
        image_features = image_features / image_features.norm(dim=1, keepdim=True)
        return image_features

    def encode_text(self, text):
        tokenized_text = self.tokenize_text(text)
        text_features = self.text_encoder(**tokenized_text).text_embeds
        text_features = text_features / text_features.norm(dim=1, keepdim=True)
        return text_features

    def compute_directional_similarity(self, img_feat_one, img_feat_two, text_feat_one, text_feat_two):
        sim_direction = F.cosine_similarity(img_feat_two - img_feat_one, text_feat_two - text_feat_one)
        return sim_direction

    def forward(self, image_one, image_two, caption_one, caption_two):
        img_feat_one = self.encode_image(image_one)
        img_feat_two = self.encode_image(image_two)
        text_feat_one = self.encode_text(caption_one)
        text_feat_two = self.encode_text(caption_two)
        directional_similarity = self.compute_directional_similarity(
        img_feat_one, img_feat_two, text_feat_one, text_feat_two
        )
        return directional_similarity
```

ุฏุนูุง ูุณุชุฎุฏู `DirectionalSimilarity` ุงูุขู.

```python
dir_similarity = DirectionalSimilarity(tokenizer, text_encoder, image_processor, image_encoder)
scores = []

for i in range(len(input_images)):
    original_image = input_images[i]
    original_caption = original_captions[i]
    edited_image = edited_images[i]
    modified_caption = modified_captions[i]

    similarity_score = dir_similarity(original_image, edited_image, original_caption, modified_caption)
    scores.append(float(similarity_score.detach().cpu()))

print(f"CLIP directional similarity: {np.mean(scores)}")
# ุชุดุงุจู ุงูุงุชุฌุงู CLIP: 0.0797976553440094
```

ูุซู ุฏุฑุฌุฉ CLIPุ ูููุง ูุงูุช ุฏุฑุฌุฉ ุงูุชุดุงุจู ุงูุงุชุฌุงูู CLIP ุฃุนููุ ูุงู ุฐูู ุฃูุถู.

ุชุฌุฏุฑ ุงูุฅุดุงุฑุฉ ุฅูู ุฃู `StableDiffusionInstructPix2PixPipeline` ุชุนุฑุถ ุญุฌุชููุ ูููุง `image_guidance_scale` ู`guidance_scale`ุ ูุงููุชุงู ุชุชูุญุงู ูู ุงูุชุญูู ูู ุฌูุฏุฉ ุงูุตูุฑุฉ ุงูููุงุฆูุฉ ุงููุนุฏูุฉ. ูุดุฌุนู ุนูู ุชุฌุฑุจุฉ ูุงุชูู ุงูุญุฌุชูู ูุฑุคูุฉ ุชุฃุซูุฑููุง ุนูู ุงูุชุดุงุจู ุงูุงุชุฌุงูู.

ูููููุง ุชูุณูุน ููุฑุฉ ูุฐุง ุงููููุงุณ ูููุงุณ ูุฏู ุชุดุงุจู ุงูุตูุฑุฉ ุงูุฃุตููุฉ ูุงููุณุฎุฉ ุงููุนุฏูุฉ. ููููุงู ุจุฐููุ ูููููุง ุจุจุณุงุทุฉ ุฅุฌุฑุงุก `F.cosine_similarity (img_feat_twoุ img_feat_one)`. ุจุงููุณุจุฉ ููุฐู ุงูุชุนุฏููุงุชุ ูุง ุฒููุง ูุฑูุฏ ุงูุญูุงุธ ุนูู ุงูุฏูุงูุงุช ุงูุฃุณุงุณูุฉ ููุตูุฑ ูุฏุฑ ุงูุฅููุงูุ ุฃู ุฏุฑุฌุฉ ุชุดุงุจู ุนุงููุฉ.

ูููููุง ุงุณุชุฎุฏุงู ูุฐู ุงูููุงููุณ ูุฎุทูุท ุงูุฃูุงุจูุจ ุงูููุงุซูุฉ ูุซู [`StableDiffusionPix2PixZeroPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/pix2pix_zero#diffusers.StableDiffusionPix2PixZeroPipeline).

<Tip>
ูุนุชูุฏ ูู ูู ุฏุฑุฌุฉ CLIP ูุงูุชุดุงุจู ุงูุงุชุฌุงูู CLIP ุนูู ูููุฐุฌ CLIPุ ููุง ูุฏ ูุฌุนู ุงูุชููููุงุช ูุชุญูุฒุฉ.
</Tip>

***ูููู ุฃู ูููู ุชูุฏูุฏ ุงูููุงููุณ ูุซู ISุ FID (ุงูุชู ุชูุช ููุงูุดุชูุง ูุงุญููุง)ุ ุฃู KID ุฃูุฑูุง ุตุนุจูุง*** ุนูุฏูุง ูููู ุงููููุฐุฌ ููุฏ ุงูุชูููู ูุฏ ุชู ุชุฏุฑูุจู ูุณุจููุง ุนูู ูุฌููุนุฉ ุจูุงูุงุช ูุจูุฑุฉ ููุตูุฑ ูุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ (ูุซู [ูุฌููุนุฉ ุจูุงูุงุช LAION-5B](https://laion.ai/blog/laion-5b/)). ููุฑุฌุน ุฐูู ุฅูู ุฃู ูุฐู ุงูููุงููุณ ุชุนุชูุฏ ุนูู ุดุจูุฉ InceptionNet (ุงููุฏุฑุจุฉ ูุณุจููุง ุนูู ูุฌููุนุฉ ุจูุงูุงุช ImageNet-1k) ุงููุณุชุฎุฏูุฉ ูุงุณุชุฎุฑุงุฌ ููุฒุงุช ุงูุตูุฑ ุงููุชูุณุทุฉ. ูุฏ ูููู ููุงู ุชุฏุงุฎู ูุญุฏูุฏ ุจูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ ุงููุณุจู ูู Stable Diffusion ููุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ ุงููุณุจู ูู InceptionNetุ ูุฐูู ูุฅููุง ููุณุช ูุฑุดุญูุง ุฌูุฏูุง ููุง ูุงุณุชุฎุฑุงุฌ ุงูููุฒุงุช.

***ูุณุงุนุฏ ุงุณุชุฎุฏุงู ุงูููุงููุณ ุงููุฐููุฑุฉ ุฃุนูุงู ูู ุชูููู ุงูููุงุฐุฌ ุงููุดุฑูุทุฉ ุจุงููุตู. ุนูู ุณุจูู ุงููุซุงูุ [DiT](https://huggingface.co/docs/diffusers/main/en/api/pipelines/dit). ุชู ุชุฏุฑูุจู ูุณุจููุง ุจุดุฑุท ุฃู ูููู ูุดุฑูุทูุง ุจูุตูู ImageNet-1k.***
### ุงูููุงุฐุฌ ุงูุชูููุฏูุฉ ุงููุดุฑูุทุฉ ุจุงููุฆุฉ

ุนุงุฏุฉู ูุง ูุชู ุงูุชุฏุฑูุจ ุงููุณุจู ููููุงุฐุฌ ุงูุชูููุฏูุฉ ุงููุดุฑูุทุฉ ุจุงููุฆุฉ ุนูู ูุฌููุนุฉ ุจูุงูุงุช ููุณููุฉ ุจุงููุฆุงุช ูุซู [ImageNet-1k](https://huggingface.co/datasets/imagenet-1k). ุชุดูู ุงูููุงููุณ ุงูุดุงุฆุนุฉ ูุชูููู ูุฐู ุงูููุงุฐุฌ ูุณุงูุฉ ูุฑุดูู ุงูุณูุงุจ ุงููุฑู (FID)ุ ููุณุงูุฉ ุงูุณูุงุจ ุงูููุงุฉ (KID)ุ ูุฏุฑุฌุฉ ุงูุงูุณูุงุจ (IS). ููู ูุฐู ุงููุซููุฉุ ูุฑูุฒ ุนูู FID ([Heusel et al.](https://arxiv.org/abs/1706.08500)). ูุณููุถุญ ููููุฉ ุญุณุงุจูุง ุจุงุณุชุฎุฏุงู [`DiTPipeline`](https://huggingface.co/docs/diffusers/api/pipelines/dit)ุ ูุงูุชู ุชุณุชุฎุฏู [ูููุฐุฌ DiT](https://arxiv.orgMultiplier-free Transformer for Image Generation) ุชุญุช ุงูุบุทุงุก.

ุชูุฏู FID ุฅูู ููุงุณ ูุฏู ุชุดุงุจู ูุฌููุนุชูู ูู ุงูุตูุฑ. ููููุง [ููุฐุง ุงูููุฑุฏ](https://mmgeneration.readthedocs.io/en/latest/quick_run.html#fid):

> ุชุนุฏ ูุณุงูุฉ ูุฑุดูู ุงูุณูุงุจ ุงููุฑู ูููุงุณูุง ูุชุดุงุจู ูุฌููุนุชูู ูู ุงูุตูุฑ. ููุฏ ุซุจุช ุฃููุง ุชุชูุงูู ุฌูุฏูุง ูุน ุงูุญูู ุงูุจุดุฑู ุนูู ุงูุฌูุฏุฉ ุงููุฑุฆูุฉุ ููุชู ุงุณุชุฎุฏุงููุง ูู ุฃุบูุจ ุงูุฃุญูุงู ูุชูููู ุฌูุฏุฉ ุงูุนููุงุช ุงูุชู ุชูุชุฌูุง ุงูุดุจูุงุช ุงูุฎุตููุฉ ุงูุชูููุฏูุฉ. ูุชู ุญุณุงุจ FID ุนู ุทุฑูู ุญุณุงุจ ูุณุงูุฉ ูุฑุดูู ุจูู ุงุซููู ูู ุงูุชูุฒูุนุงุช ุงูุงุญุชูุงููุฉ ุงูุบุงูุณูุฉ ุงูููุงุณุจุฉ ูุชูุซูู ุงูุฎุตุงุฆุต ุงูุชู ููุชุฌูุง ูููุฐุฌ Inception.

ุชุชูุซู ูุงุชุงู ุงููุฌููุนุชุงู ูู ุงูุจูุงูุงุช ุจุดูู ุฃุณุงุณู ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุตูุฑ ุงูุญููููุฉ ููุฌููุนุฉ ุจูุงูุงุช ุงูุตูุฑ ุงููุฒููุฉ (ุงูุตูุฑ ุงููููุฏุฉ ูู ุญุงูุชูุง). ูุนุงุฏุฉ ูุง ูุชู ุญุณุงุจ FID ุจุงุณุชุฎุฏุงู ูุฌููุนุชูู ูุจูุฑุชูู ูู ุงูุจูุงูุงุช. ููุน ุฐููุ ุณูุนูู ูู ูุฐู ุงููุซููุฉ ูุน ูุฌููุนุชูู ุตุบูุฑุชูู ูู ุงูุจูุงูุงุช.

ุฏุนููุง ูููู ุฃููุงู ุจุชูุฒูู ุจุนุถ ุงูุตูุฑ ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ ImageNet-1k:

```python
from zipfile import ZipFile
import requests


def download(url, local_filepath):
    r = requests.get(url)
    with open(local_filepath, "wb") as f:
        f.write(r.content)
    return local_filepath

dummy_dataset_url = "https://hf.co/datasets/sayakpaul/sample-datasets/resolve/main/sample-imagenet-images.zip"
local_filepath = download(dummy_dataset_url, dummy_dataset_url.split("/")[-1])

with ZipFile(local_filepath, "r") as zipper:
    zipper.extractall(".")
```

```python
from PIL import Image
import os

dataset_path = "sample-imagenet-images"
image_paths = sorted([os.path.join(dataset_path, x) for x in os.listdir(dataset_path)])

real_images = [np.array(Image.open(path).convert("RGB")) for path in image_paths]
```

ูุฐู 10 ุตูุฑ ูู ูุฆุงุช ImageNet-1k ุงูุชุงููุฉ: "cassette_player"ุ "chain_saw" (x2)ุ "church"ุ "gas_pump" (x3)ุ "parachute" (x2)ุ ู "tench".

<p align="center">
<img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/real-images.png" alt="real-images"><br>
<em>Real images.</em>
</p>

ุงูุขู ุจุนุฏ ุชุญููู ุงูุตูุฑุ ุฏุนูุง ูุทุจู ุจุนุถ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุงูุจุณูุทุฉ ุนูููุง ูุงุณุชุฎุฏุงููุง ูู ุญุณุงุจ FID.

```python
from torchvision.transforms import functional as F


def preprocess_image(image):
    image = torch.tensor(image).unsqueeze(0)
    image = image.permute(0, 3, 1, 2) / 255.0
    return F.center_crop(image, (256, 256))

real_images = torch.cat([preprocess_image(image) for image in real_images])
print(real_images.shape)
# torch.Size([10, 3, 256, 256])
```

ุณูููู ุงูุขู ุจุชุญููู [`DiTPipeline`](https://huggingface.co/docs/diffusers/api/pipelines/dit) ูุชูููุฏ ุงูุตูุฑ ุงููุดุฑูุทุฉ ุจุงููุฆุงุช ุงููุฐููุฑุฉ ุฃุนูุงู.

```python
from diffusers import DiTPipeline, DPMSolverMultistepScheduler

dit_pipeline = DiTPipeline.from_pretrained("facebook/DiT-XL-2-256", torch_dtype=torch.float16)
dit_pipeline.scheduler = DPMSolverMultistepScheduler.from_config(dit_pipeline.scheduler.config)
dit_pipeline = dit_pipeline.to("cuda")

words = [
    "cassette player",
    "chainsaw",
    "chainsaw",
    "church",
    "gas pump",
    "gas pump",
    "gas pump",
    "parachute",
    "parachute",
    "tench",
]

class_ids = dit_pipeline.get_label_ids(words)
output = dit_pipeline(class_labels=class_ids, generator=generator, output_type="np")

fake_images = output.images
fake_images = torch.tensor(fake_images)
fake_images = fake_images.permute(0, 3, 1, 2)
print(fake_images.shape)
# torch.Size([10, 3, 256, 256])
```

ุงูุขูุ ูููููุง ุญุณุงุจ FID ุจุงุณุชุฎุฏุงู [`torchmetrics`](https://torchmetrics.readthedocs.io/).

```python
from torchmetrics.image.fid import FrechetInceptionDistance

fid = FrechetInceptionDistance(normalize=True)
fid.update(real_images, real=True)
fid.update(fake_images, real=False)

print(f"FID: {float(fid.compute())}")
# FID: 177.7147216796875
```

ูููุง ุงูุฎูุถุช ูููุฉ FIDุ ูุงู ุฐูู ุฃูุถู. ูููู ุฃู ูุคุซุฑ ุงูุนุฏูุฏ ูู ุงูุนูุงูู ุนูู FID ููุง:

- ุนุฏุฏ ุงูุตูุฑ (ุงูุญููููุฉ ูุงููุฒููุฉ)
- ุงูุนุดูุงุฆูุฉ ูู ุนูููุฉ ุงูุงูุชุดุงุฑ
- ุนุฏุฏ ุฎุทูุงุช ุงูุงุณุชุฏูุงู ูู ุนูููุฉ ุงูุงูุชุดุงุฑ
- ุงูุฌุฏููุฉ ุงููุณุชุฎุฏูุฉ ูู ุนูููุฉ ุงูุงูุชุดุงุฑ

ุจุงููุณุจุฉ ููููุทุชูู ุงูุฃุฎูุฑุชููุ ูู ุงูุฌูุฏ ุฅุฐู ุฅุฌุฑุงุก ุงูุชูููู ุนุจุฑ ุจุฐูุฑ ูุฎุทูุงุช ุงุณุชุฏูุงู ูุฎุชููุฉุ ุซู ุงูุฅุจูุงุบ ุนู ูุชูุฌุฉ ูุชูุณุทุฉ.

<Tip warning={true}>

ุชููู ูุชุงุฆุฌ FID ุฅูู ุฃู ุชููู ูุดุฉ ูุฃููุง ุชุนุชูุฏ ุนูู ุงูุนุฏูุฏ ูู ุงูุนูุงูู:

* ูููุฐุฌ Inception ุงููุญุฏุฏ ุงููุณุชุฎุฏู ุฃุซูุงุก ุงูุญุณุงุจ.
* ุฏูุฉ ุชูููุฐ ุงูุญุณุงุจ.
* ุชูุณูู ุงูุตูุฑุฉ (ููุณ ููุณู ุฅุฐุง ุจุฏุฃูุง ูู PNGs ููุงุจู JPGs).

ูุน ูุฑุงุนุงุฉ ุฐููุ ุชููู FID ูููุฏุฉ ูู ูุซูุฑ ูู ุงูุฃุญูุงู ุนูุฏ ููุงุฑูุฉ ุงูุฌููุงุช ุงูููุงุซูุฉุ ูููู ูู ุงูุตุนุจ ุงุณุชูุณุงุฎ ูุชุงุฆุฌ ุงููุฑูุฉ ูุง ูู ููุดู ุงููุคูููู ุจุนูุงูุฉ ุนู ุฑูุฒ ููุงุณ FID.

ุชูุทุจู ูุฐู ุงูููุงุท ุฃูุถูุง ุนูู ุงูููุงููุณ ุงูุฃุฎุฑู ุฐุงุช ุงูุตูุฉุ ูุซู KID ู IS.

</Tip>

ูุฎุทูุฉ ุฃุฎูุฑุฉุ ุฏุนูุง ูููู ุจุงูุชูุชูุด ุงูุจุตุฑู ุนูู `fake_images`.

<p align="center">
<img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/fake-images.png" alt="fake-images"><br>
<em>Fake images.</em>
</p>